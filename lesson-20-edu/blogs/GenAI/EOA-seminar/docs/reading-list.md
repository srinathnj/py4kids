# GenAI Reading Lists

## 1️⃣ General Public Reading List
### Start Here
- **"AI 2041: Ten Visions for Our Future"** - Kai-Fu Lee & Chen Qiufan
  *Engaging stories that illustrate AI's future impact*
- **"The Batch" Newsletter** - Andrew Ng
  *Weekly updates in plain language*

### Core Understanding
- **"You Look Like a Thing and I Love You"** - Janelle Shane
  *Humorous, accessible intro to AI capabilities and quirks*
- **"GPT-3: The AI That Changes Everything"** - Stephen Wolfram
  *Clear explanation for non-technical readers*

### Practical Applications
- **"Prompt Engineering for Everybody"** - dair.ai
  *Basic guide to effective AI interaction*
- **OpenAI Cookbook**
  *Real-world examples and use cases*

### Broader Context
- **"Atlas of AI"** - Kate Crawford
  *Social and environmental impact of AI*
- **"Power and Prediction"** - Ajay Agrawal et al
  *Economic and business implications*

## 2️⃣ Physicist's Reading List
### Mathematical Foundations
- **"Information Theory, Pattern Recognition, and Neural Networks"** - David MacKay
  *Rigorous statistical mechanics approach to machine learning*
- **"Deep Learning and Physics"** - Koji Hashimoto
  *Connections between ML and physical theories*

### Architecture & Dynamics
- **"A Mathematical Framework for Transformer Circuits"** - Anthropic
  *Field theory perspective on attention mechanisms*
- **"The Principles of Deep Learning Theory"** - Roberts et al.
  *Mean field theory approach to neural networks*

### Statistical & Quantum Perspectives
- **"Statistical Physics of Machine Learning"** - EPFL lectures
  *Phase transitions in learning systems*
- **"Information, Physics, and Computation"** - Mézard & Montanari
  *Statistical mechanics in information processing*
- **"Quantum Machine Learning"** - Maria Schuld
  *Quantum mechanical perspectives on ML*

### Advanced Topics
- **"On the Opportunities and Risks of Foundation Models"** - Stanford CRFM
  *Rigorous analysis of scaling laws and emergent properties*
- **"Language Models are Few-Shot Learners"** - Brown et al.
  *Technical deep-dive into GPT architecture*

### Theory Development
- **"Why do Neural Networks Work?"** - Boris Hanin
  *Mathematical theory of deep learning*
- **"The Principles of Deep Learning: An Effective Theory Approach"** - MIT Press
  *Theoretical frameworks analogous to effective field theories*

### Physics-AI Interface
- **"Machine Learning and the Physical Sciences"** - Nature Reviews Physics
  *Applications and theoretical connections*
- **"Physics of Deep Learning"** - Yaida
  *Statistical mechanical theory of training dynamics*

Note for Physicists: These materials often draw parallels with:
- Renormalization group theory for understanding scaling laws
- Path integrals for sequence modeling
- Phase transitions in model capacity and learning
- Mean field theory for network behavior
- Quantum mechanics for attention mechanisms
- Statistical ensembles for probability distributions

Start with MacKay's book for foundational concepts, then explore specific areas based on your physics subspecialty.