{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to scrape google search result\n",
    "\n",
    "https://hackernoon.com/how-to-scrape-google-with-python-bo7d2tal\n",
    "\n",
    "https://serpwow.com/\n",
    "\n",
    "https://pythondata.com/quick-tip-consuming-google-search-results-to-use-for-web-scraping/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"USER_AGENT\": {\n",
    "        \"desktop\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\",\n",
    "        \"mobile\": \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"\n",
    "    },\n",
    "    \"SEARCH_BASE_URL\": {\n",
    "        \"bing\": \"https://www.bing.com/search\",\n",
    "        \"google\": \"https://google.com/search\"\n",
    "    }\n",
    "}\n",
    "\n",
    "HEADERS = {\"user-agent\" : CONFIG[\"USER_AGENT\"][\"desktop\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_url(query:str, start:int = 0, engine:str = \"google\") -> str:\n",
    "    \"\"\"Get search url\n",
    "    \n",
    "    args:\n",
    "        query (str): search text\n",
    "        start (int): starting result index\n",
    "        engine (str): \"bing\" or \"google\"\n",
    "    \"\"\"\n",
    "    engine = engine.lower()\n",
    "    query = urllib.parse.quote(query)\n",
    "\n",
    "    if engine == \"bing\":\n",
    "        url = CONFIG[\"SEARCH_BASE_URL\"][engine] + \\\n",
    "                \"?q=\"+ urllib.parse.quote(query) + \\\n",
    "                (\"\" if start==0 else f\"&first={start}\")\n",
    "    elif engine == \"google\":\n",
    "        url = CONFIG[\"SEARCH_BASE_URL\"][engine] + \\\n",
    "                \"?q=\"+ urllib.parse.quote(query) + \\\n",
    "                (\"\" if start==0 else f\"&start={start}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unimplemented search engine {engine}\")\n",
    "    \n",
    "    return url\n",
    "\n",
    "# get_search_url(\"tensorflow\", start=10, engine=\"google\")   # 'https://google.com/search?q=tensorflow&start=10'\n",
    "# get_search_url(\"tensor flow\", start=10, engine=\"bing\")   # 'https://www.bing.com/search?q=tensor%20flow&first=10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result_google(url, headers):\n",
    "    res_dic = {}  # key=link, val=title\n",
    "    resp = requests.get(url, headers=headers)\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "        for g in soup.find_all('div', class_='r'):\n",
    "            anchors = g.find_all('a')\n",
    "            if len(anchors):                \n",
    "                link = anchors[0]['href']\n",
    "                if \"http\" in link:\n",
    "                    res_dic[link] = g.find('h3').text\n",
    "\n",
    "        for g in soup.find_all('h3', class_='r'):\n",
    "            anchors = g.find_all('a')\n",
    "            if len(anchors):                \n",
    "                link = anchors[0]['href']\n",
    "                if \"http\" in link:\n",
    "                    res_dic[link] = g.text\n",
    "                    \n",
    "    results = []\n",
    "    for link,title in res_dic.items():\n",
    "        item = {\"title\": title, \"link\": link}\n",
    "        results.append(item)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = \"google\"\n",
    "search_text = \"tensorflow\"\n",
    "MAX_RESULTS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for start in range(0,MAX_RESULTS,10):\n",
    "    URL = get_search_url(search_text, start=start, engine=engine)\n",
    "    res = get_search_result_google(URL, HEADERS)\n",
    "    if len(res):\n",
    "        results.extend(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,\n",
       " [{'title': 'TensorFlow', 'link': 'https://www.tensorflow.org/'},\n",
       "  {'title': 'tensorflow/tensorflow: An Open Source Machine ... - GitHub',\n",
       "   'link': 'https://github.com/tensorflow/tensorflow'},\n",
       "  {'title': 'tensorflow Â· GitHub', 'link': 'https://github.com/tensorflow'},\n",
       "  {'title': 'TensorFlow - Wikipedia',\n",
       "   'link': 'https://en.wikipedia.org/wiki/TensorFlow'},\n",
       "  {'title': 'TensorFlow YouTube channel - TensorFlow - YouTube',\n",
       "   'link': 'https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ'},\n",
       "  {'title': 'Tutorials', 'link': 'https://www.tensorflow.org/tutorials'},\n",
       "  {'title': 'TensorFlow Core', 'link': 'https://www.tensorflow.org/overview'},\n",
       "  {'title': 'Install', 'link': 'https://www.tensorflow.org/install'},\n",
       "  {'title': 'Guide', 'link': 'https://www.tensorflow.org/guide'},\n",
       "  {'title': 'Learn', 'link': 'https://www.tensorflow.org/learn'},\n",
       "  {'title': 'Basic classification: Classify ...',\n",
       "   'link': 'https://www.tensorflow.org/tutorials/keras/classification'}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"{search_text}-{engine}.json\", \"w\") as f:\n",
    "    f.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result_bing(url, headers):\n",
    "    res_dic = {}  # key=link, val=title\n",
    "    resp = requests.get(url, headers=headers)\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "        for tag in [\"h2\", \"h3\"]:\n",
    "            for g in soup.find_all(tag):\n",
    "                anchors = g.find_all('a')\n",
    "                if len(anchors):\n",
    "                    link = anchors[0]['href']\n",
    "                    if \"http\" in link:\n",
    "                        res_dic[link] = g.text\n",
    "\n",
    "\n",
    "    results = []\n",
    "    for link,title in res_dic.items():\n",
    "        item = {\"title\": title, \"link\": link}\n",
    "        results.append(item)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = \"bing\"  # \"google\"\n",
    "search_text = \"tensorflow\"\n",
    "MAX_RESULTS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for start in range(0,MAX_RESULTS,10):\n",
    "    URL = get_search_url(search_text, start=start, engine=engine)\n",
    "    res = get_search_result_bing(URL, HEADERS)\n",
    "    if len(res):\n",
    "        results.extend(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " [{'title': 'TensorFlow', 'link': 'https://www.tensorflow.org/'},\n",
       "  {'title': 'TensorFlow - Wikipedia',\n",
       "   'link': 'https://en.wikipedia.org/wiki/TensorFlow'},\n",
       "  {'title': 'GitHub - tensorflow/tensorflow: An Open Source Machine ...',\n",
       "   'link': 'https://github.com/tensorflow/tensorflow'},\n",
       "  {'title': 'What is TensorFlow? Introduction, Architecture & Example',\n",
       "   'link': 'https://www.guru99.com/what-is-tensorflow.html'},\n",
       "  {'title': 'tensorflow · PyPI',\n",
       "   'link': 'https://pypi.org/project/tensorflow/'},\n",
       "  {'title': 'Install', 'link': 'https://www.tensorflow.org/install'},\n",
       "  {'title': 'Learn', 'link': 'https://www.tensorflow.org/learn'},\n",
       "  {'title': 'The CORE Open Source Ml Li…',\n",
       "   'link': 'https://www.tensorflow.org/overview/'},\n",
       "  {'title': 'About', 'link': 'https://www.tensorflow.org/about'},\n",
       "  {'title': 'API', 'link': 'https://www.tensorflow.org/versions'},\n",
       "  {'title': 'TFX', 'link': 'https://www.tensorflow.org/tfx'},\n",
       "  {'title': 'Learn Ml',\n",
       "   'link': 'https://www.tensorflow.org/resources/learn-ml'},\n",
       "  {'title': 'Effective Tensorflow 2',\n",
       "   'link': 'https://www.tensorflow.org/guide/effective_tf2'},\n",
       "  {'title': 'Case Studies',\n",
       "   'link': 'https://www.tensorflow.org/about/case-studies'},\n",
       "  {'title': 'Community', 'link': 'https://www.tensorflow.org/community'}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"{search_text}-{engine}.json\", \"w\") as f:\n",
    "    f.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devopsgong/projects/py4kids/lesson-30-search\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def urlopen(url, proxies=None):\n",
    "    headers = [\n",
    "        # ('User-Agent', \"Mozilla/5.0 (Windows NT 6.1; WOW64) \" \\\n",
    "        #     \"AppleWebKit/537.36 (KHTML, like Gecko) \" \\\n",
    "        #     \"Chrome/ 58.0.3029.81 Safari/537.36\"),\n",
    "        ('User-Agent', \"Mozilla/5.0 (X11; Linux x86_64) \" \\\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \" \\\n",
    "            \"Chrome/51.0.2704.103 Safari/537.36\"),\n",
    "        (\"Accept-Language\", \"en-US,en;q=0.5\"),\n",
    "    ]\n",
    "\n",
    "    if proxies is not None:\n",
    "        # print(proxies)\n",
    "        handler = urllib.request.ProxyHandler(proxies)\n",
    "        opener = urllib.request.build_opener(handler)\n",
    "    else:\n",
    "        opener = urllib.request.build_opener()\n",
    "\n",
    "    opener.addheaders = headers\n",
    "\n",
    "    with opener.open(url) as response:\n",
    "        text = response.read()\n",
    "\n",
    "    return text\n",
    "\n",
    "text = urlopen(url)\n",
    "file_html = f\"{search_text}-{engine}.html\"\n",
    "with open(file_html, \"w\") as f:\n",
    "    f.write(text.decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
