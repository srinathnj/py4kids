{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc310fba",
   "metadata": {},
   "source": [
    "# DuckDB Tutorial for Beginners (40 minutes)\n",
    "\n",
    "- https://duckdb.org/docs/\n",
    "\n",
    "- https://claude.ai/chat/2d11d485-b4bd-435a-976f-c25b4a03f0c0\n",
    "\n",
    "## Part 1: Introduction (10 minutes)\n",
    "\n",
    "### What is DuckDB?\n",
    "DuckDB is an embedded analytical database engine, similar to SQLite but optimized for analytical queries (OLAP) rather than transactional workloads (OLTP). Think of it as \"SQLite for analytics.\"\n",
    "\n",
    "### Key Features and Advantages over Pandas\n",
    "1. **Performance**: \n",
    "   - Executes queries much faster than Pandas, especially for large datasets\n",
    "   - Efficient columnar storage and vectorized query execution\n",
    "   - Better memory management - doesn't need to load entire dataset into RAM\n",
    "\n",
    "2. **SQL-first Approach**:\n",
    "   - Write familiar SQL queries instead of chaining Pandas operations\n",
    "   - More readable and maintainable code\n",
    "   - Easier transition for those with SQL background\n",
    "\n",
    "3. **Integration**:\n",
    "   - Seamless integration with Pandas (read/write DataFrames)\n",
    "   - Direct reading of Parquet, CSV, JSON files\n",
    "   - Can query data directly from files without loading into memory\n",
    "\n",
    "4. **Scale**:\n",
    "   - Handles larger-than-memory datasets efficiently\n",
    "   - Parallel query execution\n",
    "   - Better resource utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1defb3",
   "metadata": {},
   "source": [
    "## Part 2: Setup (5 minutes)\n",
    "\n",
    "### Creating a Conda Environment\n",
    "```bash\n",
    "# Create new environment with Python 3.11\n",
    "conda create -n duckdb python=3.11\n",
    "\n",
    "# Activate environment\n",
    "conda activate duckdb\n",
    "\n",
    "# Install required packages\n",
    "pip install duckdb pandas jupyter notebook pyarrow\n",
    "```\n",
    "\n",
    "### Verifying Installation\n",
    "```python\n",
    "import duckdb\n",
    "print(duckdb.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e62ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "print(duckdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73c946",
   "metadata": {},
   "source": [
    "## Part 3: Hands-on Tutorial (20 minutes)\n",
    "\n",
    "### demo-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf2afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Create a simple DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': range(1, 6),\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, 35, 28, 22],\n",
    "    'department': ['IT', 'HR', 'IT', 'Finance', 'HR']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67de98b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>28</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Eve</td>\n",
       "      <td>22</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     name  age department\n",
       "0   1    Alice   25         IT\n",
       "1   2      Bob   30         HR\n",
       "2   3  Charlie   35         IT\n",
       "3   4    David   28    Finance\n",
       "4   5      Eve   22         HR"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c64682",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_1 = \"\"\"\n",
    "SELECT department, \n",
    "           COUNT(*) as count, \n",
    "           AVG(age) as avg_age\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    ORDER BY count DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d18d758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  department  count  avg_age\n",
      "0         HR      2     26.0\n",
      "1         IT      2     30.0\n",
      "2    Finance      1     28.0\n"
     ]
    }
   ],
   "source": [
    "# Create a DuckDB connection\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Register DataFrame as a table\n",
    "con.register('employees', df)\n",
    "\n",
    "# Simple query\n",
    "result = con.execute(sql_1).fetchdf()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "421c05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_1_1 = \"\"\"\n",
    "SELECT department, \n",
    "           COUNT(*) as count, \n",
    "           AVG(age) as avg_age\n",
    "    FROM df  -- employees\n",
    "    GROUP BY department\n",
    "    ORDER BY count DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf62258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HR</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  department  count  avg_age\n",
       "0         IT      2     30.0\n",
       "1         HR      2     26.0\n",
       "2    Finance      1     28.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2 = duckdb.sql(sql_1_1).df()\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a6eae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv_emp = \"employee.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c1830c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_csv_emp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb3a1e3",
   "metadata": {},
   "source": [
    "### demo-02 - Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a32f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp = duckdb.read_csv(file_csv_emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6f7f38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬─────────┬───────┬────────────┐\n",
       "│  id   │  name   │  age  │ department │\n",
       "│ int64 │ varchar │ int64 │  varchar   │\n",
       "├───────┼─────────┼───────┼────────────┤\n",
       "│     1 │ Alice   │    25 │ IT         │\n",
       "│     2 │ Bob     │    30 │ HR         │\n",
       "│     3 │ Charlie │    35 │ IT         │\n",
       "│     4 │ David   │    28 │ Finance    │\n",
       "│     5 │ Eve     │    22 │ HR         │\n",
       "└───────┴─────────┴───────┴────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3a119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01787f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d04e1ba8",
   "metadata": {},
   "source": [
    "### demo-04 - DuckDB beats Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735cc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a10abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def panda_way(df):\n",
    "    \n",
    "    # Method 1: Pandas\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Create modulo column first\n",
    "        df['id_mod'] = df['id'] % 1000\n",
    "        result_pd = df.groupby('id_mod')['value'].mean()\n",
    "        pd_time = time.time() - start_time\n",
    "#         print(f\"Pandas time: {pd_time:.2f} seconds\")\n",
    "        return 0, f\"Pandas time: {pd_time:.2f} seconds\"\n",
    "    except MemoryError:\n",
    "#         print(\"Pandas crashed - Out of memory!\")\n",
    "        return -1, \"Pandas crashed - Out of memory!\"\n",
    "\n",
    "def duck_way(df):\n",
    "    # Method 2: DuckDB    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        result_duck = duckdb.sql(f\"\"\"\n",
    "            WITH d0 AS (\n",
    "                SELECT *, (id - (id/1000)*1000) as id_mod FROM df\n",
    "            )\n",
    "            SELECT id_mod, avg(value) as avg_value\n",
    "            FROM d0\n",
    "            GROUP BY id_mod\n",
    "        \"\"\").df()\n",
    "        duck_time = time.time() - start_time\n",
    "#         print(f\"DuckDB time: {duck_time:.2f} seconds\")\n",
    "        return 0, f\"DuckDB time: {duck_time:.2f} seconds\"\n",
    "    except Exception as e: \n",
    "        return -1, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5779f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows: 10000000 ...\n",
      "0 Pandas time: 0.28 seconds\n",
      "0 DuckDB time: 0.10 seconds\n",
      "n_rows: 50000000 ...\n",
      "0 Pandas time: 1.44 seconds\n",
      "0 DuckDB time: 0.10 seconds\n",
      "n_rows: 100000000 ...\n",
      "0 Pandas time: 3.80 seconds\n",
      "0 DuckDB time: 0.19 seconds\n",
      "n_rows: 500000000 ...\n",
      "0 Pandas time: 76.95 seconds\n",
      "0 DuckDB time: 1.93 seconds\n",
      "n_rows: 1000000000 ...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.9 GiB for an array with shape (2, 1000000000) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12392\\1904405495.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"n_rows: {n_rows} ...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# prepare dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     df = pd.DataFrame({\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;34m'value'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"block\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         return create_block_manager_from_column_arrays(\n\u001b[0m\u001b[0;32m    155\u001b[0m             \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate)\u001b[0m\n\u001b[0;32m   2197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2198\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2199\u001b[1;33m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_form_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2200\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2201\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate)\u001b[0m\n\u001b[0;32m   2271\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2274\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_dtlike\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_wrapped_if_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2310\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2312\u001b[1;33m     \u001b[0mstacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2313\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2314\u001b[0m         \u001b[0mstacked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.9 GiB for an array with shape (2, 1000000000) and data type int64"
     ]
    }
   ],
   "source": [
    "# Generate a large dataset (adjust size based on your demo machine)\n",
    "for n_rows in [10_000_000, 50_000_000, 100_000_000, \n",
    "               500_000_000, \n",
    "               # 1_000_000_000,\n",
    "              ]:\n",
    "    \n",
    "    print(f\"n_rows: {n_rows} ...\")\n",
    "    \n",
    "    # prepare dataframe \n",
    "    df = pd.DataFrame({\n",
    "        'id': range(n_rows),\n",
    "        'value': range(n_rows)\n",
    "    })\n",
    "    # test panda\n",
    "    ncode, msg = panda_way(df)\n",
    "    print(ncode, msg)\n",
    "    # test duck\n",
    "    ncode, msg = duck_way(df)\n",
    "    print(ncode, msg)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2405bfd",
   "metadata": {},
   "source": [
    "~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py in _stack_arrays(tuples, dtype)\n",
    "   2310     shape = (len(arrays),) + first.shape\n",
    "   2311 \n",
    "-> 2312     stacked = np.empty(shape, dtype=dtype)\n",
    "   2313     for i, arr in enumerate(arrays):\n",
    "   2314         stacked[i] = arr\n",
    "\n",
    "MemoryError: Unable to allocate 14.9 GiB for an array with shape (2, 1000000000) and data type int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee1467",
   "metadata": {},
   "source": [
    "This is a fantastic demonstration of the performance differences between Pandas and DuckDB! Let me analyze the key insights from your results:\n",
    "\n",
    "Dataset Size Progression:\n",
    "- 10M rows: Pandas (0.28s) vs DuckDB (0.10s) - ~2.8x faster\n",
    "- 50M rows: Pandas (1.44s) vs DuckDB (0.10s) - ~14.4x faster\n",
    "- 100M rows: Pandas (3.80s) vs DuckDB (0.15s) - ~25.3x faster\n",
    "- 500M rows: Pandas (76.95s) vs DuckDB (1.93s) - ~39.9x faster\n",
    "- 1B rows: Pandas (MemoryError) vs DuckDB (would likely work)\n",
    "\n",
    "Key Observations:\n",
    "1. The performance gap widens dramatically as data size increases\n",
    "2. Pandas hit a memory error trying to allocate 14.9 GB for an array with shape (2, 1000000000)\n",
    "3. DuckDB maintains near-linear scaling with data size\n",
    "4. Pandas performance degradation is super-linear with size\n",
    "\n",
    "This clearly demonstrates:\n",
    "- DuckDB's superior memory efficiency through out-of-core processing\n",
    "- The limitations of Pandas' in-memory model\n",
    "- Why DuckDB is better suited for large-scale data analysis\n",
    "\n",
    "It's particularly interesting that DuckDB maintained sub-2-second performance even at 500M rows while Pandas took over a minute before failing completely at 1B rows. This is exactly the kind of real-world benchmark that helps people understand when to choose each tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3057e",
   "metadata": {},
   "source": [
    "## Part 3: Hands-on Tutorial (20 minutes)\n",
    "\n",
    "### A. Data Import\n",
    "```python\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection\n",
    "con = duckdb.connect()\n",
    "\n",
    "# CSV Import\n",
    "con.sql(\"\"\"\n",
    "    CREATE TABLE users AS \n",
    "    SELECT * FROM read_csv_auto('users.csv')\n",
    "\"\"\")\n",
    "\n",
    "# Parquet Import\n",
    "con.sql(\"\"\"\n",
    "    CREATE TABLE transactions AS \n",
    "    SELECT * FROM read_parquet('transactions.parquet')\n",
    "\"\"\")\n",
    "\n",
    "# JSON Import\n",
    "con.sql(\"\"\"\n",
    "    CREATE TABLE events AS \n",
    "    SELECT * FROM read_json_auto('events.json')\n",
    "\"\"\")\n",
    "\n",
    "# From Pandas DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "con.sql(\"SELECT * FROM df\")  # Direct query on DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eaa4bb",
   "metadata": {},
   "source": [
    "### B. SQL Operations on DataFrames\n",
    "```python\n",
    "# Basic queries\n",
    "result = con.sql(\"\"\"\n",
    "    SELECT \n",
    "        user_id,\n",
    "        COUNT(*) as transaction_count,\n",
    "        SUM(amount) as total_spent\n",
    "    FROM transactions\n",
    "    GROUP BY user_id\n",
    "    ORDER BY total_spent DESC\n",
    "    LIMIT 5\n",
    "\"\"\").df()\n",
    "\n",
    "# Joins\n",
    "result = con.sql(\"\"\"\n",
    "    SELECT \n",
    "        u.name,\n",
    "        t.transaction_date,\n",
    "        t.amount\n",
    "    FROM users u\n",
    "    JOIN transactions t ON u.id = t.user_id\n",
    "    WHERE t.amount > 1000\n",
    "\"\"\").df()\n",
    "\n",
    "# Window Functions\n",
    "result = con.sql(\"\"\"\n",
    "    SELECT \n",
    "        *,\n",
    "        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY amount DESC) as rank\n",
    "    FROM transactions\n",
    "\"\"\").df()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9c81c",
   "metadata": {},
   "source": [
    "### C. Large Dataset Analysis\n",
    "```python\n",
    "# Reading a large Parquet file (>RAM size)\n",
    "con.sql(\"\"\"\n",
    "    SELECT \n",
    "        date_trunc('month', transaction_date) as month,\n",
    "        COUNT(*) as transaction_count,\n",
    "        SUM(amount) as total_amount,\n",
    "        AVG(amount) as avg_amount\n",
    "    FROM read_parquet('large_transactions.parquet')\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\").df()\n",
    "\n",
    "# Efficient joins with large datasets\n",
    "con.sql(\"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        COUNT(DISTINCT user_id) as unique_users,\n",
    "        SUM(amount) as total_spent\n",
    "    FROM read_parquet('large_transactions.parquet') t\n",
    "    JOIN read_parquet('large_users.parquet') u \n",
    "        ON t.user_id = u.id\n",
    "    GROUP BY category\n",
    "    HAVING total_spent > 1000000\n",
    "\"\"\").df()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd04f6",
   "metadata": {},
   "source": [
    "## Part 4: Resources (5 minutes)\n",
    "\n",
    "### GitHub Repositories\n",
    "1. DuckDB Main Repository: https://github.com/duckdb/duckdb\n",
    "2. DuckDB Examples: https://github.com/duckdb/duckdb-example-repository\n",
    "3. DuckDB Tools: https://github.com/duckdb/duckdb-tools\n",
    "\n",
    "### Essential Blog Posts\n",
    "1. \"Why DuckDB\" by Mark Raasveldt and Hannes Mühleisen\n",
    "2. \"DuckDB vs Pandas\" performance comparison\n",
    "3. \"DuckDB Best Practices\" on the official blog\n",
    "\n",
    "### YouTube Videos\n",
    "1. \"Introduction to DuckDB\" by the DuckDB team\n",
    "2. \"DuckDB for Data Scientists\" tutorials\n",
    "3. Conference talks from PyData and other events\n",
    "\n",
    "### Documentation\n",
    "- Official Documentation: https://duckdb.org/docs/\n",
    "- SQL Reference: https://duckdb.org/docs/sql/introduction\n",
    "- Python API: https://duckdb.org/docs/api/python/overview\n",
    "\n",
    "## Practice Exercises\n",
    "1. Import a CSV file and perform basic aggregations\n",
    "2. Join multiple data sources and analyze relationships\n",
    "3. Use window functions for time-series analysis\n",
    "4. Handle a large dataset (>RAM) efficiently\n",
    "\n",
    "## Next Steps\n",
    "- Explore DuckDB extensions (HTTPFS, SQLite scanner, etc.)\n",
    "- Learn about materialized views and indexes\n",
    "- Understand parallel query execution\n",
    "- Practice with real-world datasets\n",
    "\n",
    "Remember to emphasize:\n",
    "- The importance of SQL knowledge\n",
    "- Memory efficiency advantages\n",
    "- Integration capabilities with existing tools\n",
    "- When to use DuckDB vs alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de473283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
