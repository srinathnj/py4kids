{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd9f70a-3768-4cf3-8dfb-a8d7460da280",
   "metadata": {},
   "source": [
    "## Use CrewAI\n",
    "\n",
    "- [GitHub](https://github.com/joaomdmoura/crewai/)\n",
    "- [Docs](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/)\n",
    "\n",
    "### Quick Overview\n",
    "\n",
    "Top-down approach\n",
    "- Goal: What is the crew for? (define the use-case)\n",
    "- Define all the Tasks required to achieve the goal? (including human review/action)\n",
    "- Define and Assign the agent(s) required to complete each task\n",
    "- Define Tools (maybe used by Agent/Task)\n",
    "- Kickoff Crew process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f4ed5f2-61fd-46d8-9857-021287b6aa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/papagame/anaconda3/envs/crewai/lib/python311.zip',\n",
       " '/home/papagame/anaconda3/envs/crewai/lib/python3.11',\n",
       " '/home/papagame/anaconda3/envs/crewai/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages',\n",
       " '/home/papagame/Documents/Dad/0-vault/api_keys/apikeystore']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7702f2d-0f50-42d1-ba5e-9c8573d18115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key_store import ApiKeyStore\n",
    "s = ApiKeyStore()\n",
    "\n",
    "openai_api_key = s.get_api_key(provider=\"OPENAI\")\n",
    "serp_api_key = s.get_api_key(provider=\"SerpApi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c756b3e2-7d65-46dc-920a-a880671a1652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['OPENAI', 'MICROSOFT', 'GOOGLE', 'HUGGING_FACE', 'WOLFRAM_ALPHA', 'ANTHROPIC', 'COHERE', 'SerpApi', 'Browserless', 'DeepL'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.api_providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6becc7-d520-422c-9ca8-07e99668c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPER_API_KEY\"] = serp_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39df715-0ad7-4022-ab11-02901175c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crewai\n",
      "  Downloading crewai-0.30.11-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting appdirs<2.0.0,>=1.4.4 (from crewai)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from crewai)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting embedchain<0.2.0,>=0.1.98 (from crewai)\n",
      "  Downloading embedchain-0.1.108-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting instructor<0.6.0,>=0.5.2 (from crewai)\n",
      "  Downloading instructor-0.5.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain<0.2.0,>=0.1.10 (from crewai)\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai<2.0.0,>=1.13.3 (from crewai)\n",
      "  Using cached openai-1.33.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
      "  Using cached opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
      "  Using cached opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.4.2 (from crewai)\n",
      "  Using cached pydantic-2.7.3-py3-none-any.whl.metadata (108 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from crewai)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting regex<2024.0.0,>=2023.12.25 (from crewai)\n",
      "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m398.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai) (4.12.3)\n",
      "Collecting chromadb<0.6.0,>=0.5.0 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_aiplatform-1.54.1-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading gptcache-0.1.43-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading langchain_cohere-0.1.7-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting posthog<4.0.0,>=3.0.2 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting rich<14.0.0,>=13.7.0 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting sqlalchemy<3.0.0,>=2.0.27 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached SQLAlchemy-2.0.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting tiktoken<0.8.0,>=0.7.0 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.3 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Using cached tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typer<0.10.0,>=0.9.0 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai) (6.0.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langsmith-0.1.77-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.13.3->crewai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.13.3->crewai)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.12.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3.0.0,>=2.4.2->crewai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3.0.0,>=2.4.2->crewai)\n",
      "  Using cached pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain<0.2.0,>=0.1.98->crewai) (2.5)\n",
      "Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached onnxruntime-1.18.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading orjson-3.10.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m320.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_auth-2.30.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (24.1)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading shapely-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: certifi in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (0.14.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.1,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Using cached zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading cohere-5.5.7-py3-none-any.whl.metadata (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading langchain_cohere-0.1.5-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging>=14.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (2.2.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai) (2.18.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3.0.0,>=2.0.27->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting boto3<2.0.0,>=1.34.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading boto3-1.34.124-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fastavro-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading types_requests-2.32.0.20240602-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (3.1.4)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai) (3.0.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (69.5.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai) (2.1.5)\n",
      "Collecting botocore<1.35.0,>=1.34.124 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading botocore-1.34.124-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is looking at multiple versions of fastapi-cli to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fastapi_cli-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading fastapi_cli-0.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fastapi>=0.95.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting filelock (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading crewai-0.30.11-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m630.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading embedchain-0.1.108-py3-none-any.whl (195 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.2/195.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
      "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached openai-1.33.0-py3-none-any.whl (325 kB)\n",
      "Using cached opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "Using cached opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "Using cached pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
      "Using cached pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "Using cached chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading google_cloud_aiplatform-1.54.1-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "Downloading gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading langchain_cohere-0.1.5-py3-none-any.whl (30 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.77-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Using cached SQLAlchemy-2.0.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m717.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m44.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
      "Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading cohere-5.5.7-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.30.0-py2.py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.7/193.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl (238 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.5/238.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.7/333.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (620 kB)\n",
      "Using cached grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m775.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached onnxruntime-1.18.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading orjson-3.10.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m613.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading shapely-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.124-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Using cached httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Downloading types_requests-2.32.0.20240602-py3-none-any.whl (15 kB)\n",
      "Using cached uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "Using cached watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading botocore-1.34.124-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: schema, pypika, mpmath, monotonic, mmh3, flatbuffers, appdirs, zipp, wrapt, websockets, uvloop, types-requests, tqdm, tenacity, sympy, regex, python-dotenv, pysbd, pyproject_hooks, pypdf, pydantic-core, pyasn1, protobuf, parameterized, packaging, orjson, opentelemetry-util-http, oauthlib, numpy, mypy-extensions, multidict, mdurl, Mako, jsonpatch, jmespath, importlib-resources, humanfriendly, httpx-sse, httptools, grpcio, greenlet, google-crc32c, fsspec, frozenlist, filelock, fastavro, docstring-parser, distro, click, cachetools, bcrypt, backoff, asgiref, annotated-types, yarl, watchfiles, uvicorn, typing-inspect, typer, tiktoken, starlette, sqlalchemy, shapely, rsa, requests-oauthlib, pydantic, pyasn1-modules, proto-plus, posthog, opentelemetry-proto, marshmallow, markdown-it-py, importlib-metadata, huggingface_hub, gptcache, googleapis-common-protos, google-resumable-media, deprecated, coloredlogs, chroma-hnswlib, build, botocore, aiosignal, tokenizers, s3transfer, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, onnxruntime, langsmith, grpcio-status, google-auth, fastapi, dataclasses-json, alembic, aiohttp, opentelemetry-semantic-conventions, opentelemetry-instrumentation, langchain-core, kubernetes, instructor, grpc-google-iam-v1, google-api-core, boto3, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-text-splitters, langchain-openai, langchain-community, google-cloud-core, cohere, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-cohere, langchain, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform, chromadb, embedchain, crewai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "Successfully installed Mako-1.3.5 aiohttp-3.9.5 aiosignal-1.3.1 alembic-1.13.1 annotated-types-0.7.0 appdirs-1.4.4 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 boto3-1.34.124 botocore-1.34.124 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.5.0 click-8.1.7 cohere-5.5.7 coloredlogs-15.0.1 crewai-0.30.11 dataclasses-json-0.6.7 deprecated-1.2.14 distro-1.9.0 docstring-parser-0.15 embedchain-0.1.108 fastapi-0.110.3 fastavro-1.9.4 filelock-3.14.0 flatbuffers-24.3.25 frozenlist-1.4.1 fsspec-2024.6.0 google-api-core-2.19.0 google-auth-2.30.0 google-cloud-aiplatform-1.54.1 google-cloud-bigquery-3.24.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.17.0 google-crc32c-1.5.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.1 gptcache-0.1.43 greenlet-3.0.3 grpc-google-iam-v1-0.13.0 grpcio-1.64.1 grpcio-status-1.62.2 httptools-0.6.1 httpx-sse-0.4.0 huggingface_hub-0.23.3 humanfriendly-10.0 importlib-metadata-7.1.0 importlib-resources-6.4.0 instructor-0.5.2 jmespath-1.0.1 jsonpatch-1.33 kubernetes-30.1.0 langchain-0.1.20 langchain-cohere-0.1.5 langchain-community-0.0.38 langchain-core-0.1.52 langchain-openai-0.1.7 langchain-text-splitters-0.0.2 langsmith-0.1.77 markdown-it-py-3.0.0 marshmallow-3.21.3 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.18.0 openai-1.33.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-exporter-otlp-proto-http-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.4 packaging-23.2 parameterized-0.9.0 posthog-3.5.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.7.3 pydantic-core-2.18.4 pypdf-4.2.0 pypika-0.48.9 pyproject_hooks-1.1.0 pysbd-0.3.4 python-dotenv-1.0.1 regex-2023.12.25 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 s3transfer-0.10.1 schema-0.7.7 shapely-2.0.4 sqlalchemy-2.0.30 starlette-0.37.2 sympy-1.12.1 tenacity-8.3.0 tiktoken-0.7.0 tokenizers-0.15.2 tqdm-4.66.4 typer-0.9.4 types-requests-2.32.0.20240602 typing-inspect-0.9.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0 wrapt-1.16.0 yarl-1.9.4 zipp-3.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83238af-1c98-442f-9b93-dfd751f5ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crewai[tools] in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (0.30.11)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (1.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (8.1.7)\n",
      "Collecting crewai-tools<0.3.0,>=0.2.6 (from crewai[tools])\n",
      "  Downloading crewai_tools-0.2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: embedchain<0.2.0,>=0.1.98 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (0.1.108)\n",
      "Requirement already satisfied: instructor<0.6.0,>=0.5.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (0.5.2)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.10 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (0.1.20)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (1.33.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (1.25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (2.7.3)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (1.0.1)\n",
      "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai[tools]) (2023.12.25)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (4.12.3)\n",
      "Collecting chromadb<0.5.0,>=0.4.22 (from crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docx2txt<0.9,>=0.8 (from crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lancedb<0.6.0,>=0.5.4 (from crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading lancedb-0.5.7-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pyright<2.0.0,>=1.1.350 (from crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading pyright-1.1.366-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pytest<9.0.0,>=8.0.0 (from crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading pytest-8.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pytube<16.0.0,>=15.0.0 (from crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (2.32.3)\n",
      "Collecting selenium<5.0.0,>=4.18.1 (from crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading selenium-4.21.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.13.1)\n",
      "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting embedchain<0.2.0,>=0.1.98 (from crewai[tools])\n",
      "  Downloading embedchain-0.1.107-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading embedchain-0.1.106-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading embedchain-0.1.105-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading embedchain-0.1.104-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading embedchain-0.1.103-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading embedchain-0.1.102-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.54.1)\n",
      "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (0.1.43)\n",
      "Collecting langchain-openai<0.0.6,>=0.0.5 (from embedchain<0.2.0,>=0.1.98->crewai[tools])\n",
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: posthog<4.0.0,>=3.0.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (3.5.0)\n",
      "Collecting pypdf<4.0.0,>=3.11.0 (from embedchain<0.2.0,>=0.1.98->crewai[tools])\n",
      "  Downloading pypdf-3.17.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (0.3.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (13.7.1)\n",
      "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (0.7.7)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.0.30)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from embedchain<0.2.0,>=0.1.98->crewai[tools])\n",
      "  Downloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (3.9.5)\n",
      "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (0.15)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (8.3.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (0.9.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (6.0.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.6.7)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (1.26.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (4.12.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (7.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.63.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.25.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (4.25.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai[tools]) (0.46b0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.4.2->crewai[tools]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.4.2->crewai[tools]) (2.18.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.9.4)\n",
      "Requirement already satisfied: Mako in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.3.5)\n",
      "Requirement already satisfied: idna>=2.8 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai[tools]) (3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (2.5)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.2.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.110.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.30.1)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading pulsar_client-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.18.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.46b0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.64.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (4.1.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (3.10.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (1.16.0)\n",
      "Collecting PyGithub<2.0.0,>=1.59.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading PyGithub-1.59.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "INFO: pip is looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gitpython<4.0.0,>=3.1.38 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl.metadata (160 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.19.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.30.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.23.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.17.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (3.24.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.0.4)\n",
      "Requirement already satisfied: cachetools in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.98->crewai[tools]) (5.3.3)\n",
      "Requirement already satisfied: certifi in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (3.19.2)\n",
      "Collecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyarrow>=12 (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Using cached pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai[tools]) (1.33)\n",
      "Requirement already satisfied: six>=1.5 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.9.0.post0)\n",
      "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting iniconfig (from pytest<9.0.0,>=8.0.0->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2.0,>=1.5 (from pytest<9.0.0,>=8.0.0->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai[tools]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.18.0)\n",
      "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading trio-0.25.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain<0.2.0,>=0.1.98->crewai[tools]) (3.0.3)\n",
      "Requirement already satisfied: pyproject_hooks in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.1.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.37.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.62.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.7.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (1.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai[tools]) (3.0.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (3.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai[tools]) (0.1.2)\n",
      "Requirement already satisfied: coloredlogs in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (24.3.25)\n",
      "Requirement already satisfied: sympy in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.12.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (69.5.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (3.8.1)\n",
      "Collecting pyjwt>=2.4.0 (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (5.1.1)\n",
      "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.23.3)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (1.0.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.18.1->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (12.0)\n",
      "Collecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (2.1.5)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: filelock in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (2024.6.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai[tools]) (0.6.0)\n",
      "Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools])\n",
      "  Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.3.0,>=0.2.6->crewai[tools]) (2.22)\n",
      "Downloading crewai_tools-0.2.6-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m488.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading embedchain-0.1.102-py3-none-any.whl (192 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m798.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
      "Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyright-1.1.366-py3-none-any.whl (18 kB)\n",
      "Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.9/339.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m869.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m70.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading pulsar_client-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m364.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
      "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
      "Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=bdf5d60af48d43576280a0add3b1d30a7362334d5bfea56b5de2ff6f5ea15555\n",
      "  Stored in directory: /home/papagame/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: sortedcontainers, ratelimiter, docx2txt, brotli, wsproto, smmap, semver, pytube, pysocks, pypdf, pyjwt, pycryptodomex, pyarrow, py, pulsar-client, pluggy, outcome, nodeenv, mutagen, iniconfig, deprecation, yt_dlp, youtube-transcript-api, trio, tiktoken, retry, pytest, pyright, pynacl, pylance, gitdb, cryptography, trio-websocket, lancedb, gitpython, selenium, PyGithub, langchain-openai, chromadb, embedchain, crewai-tools\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 4.2.0\n",
      "    Uninstalling pypdf-4.2.0:\n",
      "      Successfully uninstalled pypdf-4.2.0\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.7.0\n",
      "    Uninstalling tiktoken-0.7.0:\n",
      "      Successfully uninstalled tiktoken-0.7.0\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.1.7\n",
      "    Uninstalling langchain-openai-0.1.7:\n",
      "      Successfully uninstalled langchain-openai-0.1.7\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.5.0\n",
      "    Uninstalling chromadb-0.5.0:\n",
      "      Successfully uninstalled chromadb-0.5.0\n",
      "  Attempting uninstall: embedchain\n",
      "    Found existing installation: embedchain 0.1.108\n",
      "    Uninstalling embedchain-0.1.108:\n",
      "      Successfully uninstalled embedchain-0.1.108\n",
      "Successfully installed PyGithub-1.59.1 brotli-1.1.0 chromadb-0.4.24 crewai-tools-0.2.6 cryptography-42.0.8 deprecation-2.1.0 docx2txt-0.8 embedchain-0.1.102 gitdb-4.0.11 gitpython-3.1.43 iniconfig-2.0.0 lancedb-0.5.7 langchain-openai-0.0.5 mutagen-1.47.0 nodeenv-1.9.1 outcome-1.3.0.post0 pluggy-1.5.0 pulsar-client-3.5.0 py-1.11.0 pyarrow-16.1.0 pycryptodomex-3.20.0 pyjwt-2.8.0 pylance-0.9.18 pynacl-1.5.0 pypdf-3.17.4 pyright-1.1.366 pysocks-1.7.1 pytest-8.2.2 pytube-15.0.0 ratelimiter-1.2.0.post0 retry-0.9.2 selenium-4.21.0 semver-3.0.2 smmap-5.0.1 sortedcontainers-2.4.0 tiktoken-0.5.2 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0 youtube-transcript-api-0.6.2 yt_dlp-2023.12.30\n"
     ]
    }
   ],
   "source": [
    "!pip install 'crewai[tools]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae950063-92f8-4c80-9fbc-7a362745cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "from crewai_tools import SerperDevTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a845714a-8ceb-4ee1-81a7-b79b8e132093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2242813f-fdcc-411c-b43a-c29ef2710511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: crewai\n",
      "Version: 0.30.11\n",
      "Summary: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\n",
      "Home-page: \n",
      "Author: Joao Moura\n",
      "Author-email: joao@crewai.com\n",
      "License: \n",
      "Location: /home/papagame/anaconda3/envs/crewai/lib/python3.11/site-packages\n",
      "Requires: appdirs, click, embedchain, instructor, langchain, openai, opentelemetry-api, opentelemetry-exporter-otlp-proto-http, opentelemetry-sdk, pydantic, python-dotenv, regex\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show crewai   # 0.30.11"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5459f4e3-d88c-4b35-8948-713bae79588c",
   "metadata": {},
   "source": [
    "ame: crewai\n",
    "Version: 0.30.11\n",
    "Summary: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\n",
    "Home-page: \n",
    "Author: Joao Moura\n",
    "Author-email: joao@crewai.com\n",
    "License: \n",
    "Location: /home/gongai/anaconda3/envs/crewai/lib/python3.11/site-packages\n",
    "Requires: appdirs, click, embedchain, instructor, langchain, openai, opentelemetry-api, opentelemetry-exporter-otlp-proto-http, opentelemetry-sdk, pydantic, python-dotenv, regex\n",
    "Required-by: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607b31b-4a10-46be-9a21-0b412d407af5",
   "metadata": {},
   "source": [
    "### Enter topic of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352458ca-0670-4d97-b880-6e856c4d7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'AI Research by Google'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5bf496-99a9-40e8-ab42-5aea8de04049",
   "metadata": {},
   "source": [
    "### Step 1: Assemble Your Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436827e-8bfd-4ffe-9781-ae0e8208a9e2",
   "metadata": {},
   "source": [
    "#### Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f0073f-f80a-49fc-bddc-d1f9966cea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = SerperDevTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc23ce-121d-4c26-a5fa-42e4233abc5a",
   "metadata": {},
   "source": [
    "#### Define Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5311128d-0894-4979-bac8-d15200c27f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a senior researcher agent with memory and verbose mode\n",
    "researcher = Agent(\n",
    "  role='Senior Researcher',\n",
    "  goal='Uncover groundbreaking technologies in {topic}',\n",
    "  verbose=True,\n",
    "  memory=True,\n",
    "  backstory=(\n",
    "    \"Driven by curiosity, you're at the forefront of\"\n",
    "    \"innovation, eager to explore and share knowledge that could change\"\n",
    "    \"the world.\"\n",
    "  ),\n",
    "  tools=[search_tool],\n",
    "  allow_delegation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a85614-81fc-4b1a-8755-ee4a8d2e69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a writer agent with custom tools and delegation capability\n",
    "writer = Agent(\n",
    "  role='Writer',\n",
    "  goal='Narrate compelling tech stories about {topic}',\n",
    "  verbose=True,\n",
    "  memory=True,\n",
    "  backstory=(\n",
    "    \"With a flair for simplifying complex topics, you craft\"\n",
    "    \"engaging narratives that captivate and educate, bringing new\"\n",
    "    \"discoveries to light in an accessible manner.\"\n",
    "  ),\n",
    "  tools=[search_tool],\n",
    "  allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10f2df-3f8f-46d6-ba99-eb8c02aee3e5",
   "metadata": {},
   "source": [
    "### Step 2: Define the Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b8fe0c-1ec0-4037-b038-d268f3caabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "\n",
    "# Research task\n",
    "research_task = Task(\n",
    "  description=(\n",
    "    \"Identify the next big trend in {topic}.\"\n",
    "    \"Focus on identifying pros and cons and the overall narrative.\"\n",
    "    \"Your final report should clearly articulate the key points,\"\n",
    "    \"its market opportunities, and potential risks.\"\n",
    "  ),\n",
    "  expected_output='A comprehensive 3 paragraphs long report on the latest AI trends.',\n",
    "  tools=[search_tool],\n",
    "  agent=researcher,\n",
    ")\n",
    "\n",
    "# Writing task with language model configuration\n",
    "write_task = Task(\n",
    "  description=(\n",
    "    \"Compose an insightful article on {topic}.\"\n",
    "    \"Focus on the latest trends and how it's impacting the industry.\"\n",
    "    \"This article should be easy to understand, engaging, and positive.\"\n",
    "  ),\n",
    "  expected_output='A 4 paragraph article on {topic} advancements formatted as markdown.',\n",
    "  tools=[search_tool],\n",
    "  agent=writer,\n",
    "  async_execution=False,\n",
    "  output_file='new-blog-post.md'  # Example of output customization\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7ea12-3e11-44e8-8b2b-39edbb353497",
   "metadata": {},
   "source": [
    "### Step 3: Form the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f463a9dd-0b8b-49c0-a913-25f03f052043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "\n",
    "# Forming the tech-focused crew with some enhanced configurations\n",
    "crew = Crew(\n",
    "  agents=[researcher, writer],\n",
    "  tasks=[research_task, write_task],\n",
    "  process=Process.sequential,  # Optional: Sequential task execution is default\n",
    "  memory=True, # False,  # \n",
    "  cache=True, # False,   # \n",
    "  max_rpm=50,\n",
    "  # share_crew=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3c594-4119-4b8d-ae85-94a38ddeed19",
   "metadata": {},
   "source": [
    "\n",
    "Issue:\n",
    "```\n",
    "OperationalError                          Traceback (most recent call last)\n",
    "File ~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1967, in Connection._exec_single_context(self, dialect, context, statement, parameters)\n",
    "   1966     if not evt_handled:\n",
    "-> 1967         self.dialect.do_execute(\n",
    "   1968             cursor, str_statement, effective_parameters, context\n",
    "   1969         )\n",
    "   1971 if self._has_events or self.engine._has_events:\n",
    "```\n",
    "root-cause:\n",
    "\n",
    "```\n",
    "which jupyter\n",
    "/home/gongai/.local/bin/jupyter\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776915d-c82d-4f4d-802a-db21c260febc",
   "metadata": {},
   "source": [
    "### Step 4: Kick It Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564f30f-b631-46a4-860d-195e030e93bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f145ed-8d6a-4a2c-8f9f-5e5331ae1741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo begin this task, I need to get the latest information on AI Research by Google. The best tool to use for this would be the \"Search the internet\" tool to find recent articles, blog posts or press releases about Google's AI research projects.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"latest AI Research by Google\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google Research - Explore Our Latest Research in Science and AI\n",
      "Link: http://research.google/\n",
      "Snippet: Discover Google Research. We publish research papers across a wide range of domains and share our latest developments in AI and science research.\n",
      "---\n",
      "Title: Research - Google AI\n",
      "Link: https://ai.google/discover/research/\n",
      "Snippet: RESEARCH: Tackling the most challenging problems in computer science. Our teams aspire to make discoveries that positively impact society.\n",
      "---\n",
      "Title: Making AI helpful for everyone - Google AI – Google AI\n",
      "Link: https://ai.google/\n",
      "Snippet: Our AI innovations are built using our responsible AI practices and led by teams at Google DeepMind and Google Research. Learn more. Guided by principles ...\n",
      "---\n",
      "Title: Blog – Google Research\n",
      "Link: http://research.google/blog/\n",
      "Snippet: The latest research from Google · Conferences & Events · Generative AI · Health & Bioscience · Machine Intelligence · Product · Quantum · Responsible AI ...\n",
      "---\n",
      "Title: Latest AI Developments at Google - AI News\n",
      "Link: https://www.artificialintelligence-news.com/categories/ai-companies/google/\n",
      "Snippet: Google has unveiled a series of updates to its AI offerings, including the introduction of Gemini 1.5 Flash, enhancements to Gemini 1.5 Pro, and progress on ...\n",
      "---\n",
      "Title: Google Labs\n",
      "Link: https://labs.google/\n",
      "Snippet: Try the latest AI experiments in Search, and get AI Overviews on even more topics in Labs. Ask anything, get inspired, and easily find what you're looking for.\n",
      "---\n",
      "Title: Google AI: New insights from 6 images of the human brain\n",
      "Link: https://blog.google/technology/research/google-ai-research-new-images-human-brain/\n",
      "Snippet: Google researchers and Harvard neuroscientists have worked together to reveal incredible images of the human brain.\n",
      "---\n",
      "Title: Publications - Google DeepMind\n",
      "Link: https://deepmind.google/research/publications/\n",
      "Snippet: Publications. Explore a selection of our recent research on some of the most complex and interesting challenges in AI.\n",
      "---\n",
      "Title: People + AI Research - Google\n",
      "Link: https://pair.withgoogle.com/\n",
      "Snippet: Our research into computer science, HCI, and design focuses on making ML more understandable, trustworthy, reliably fair, and useful. Browse our collection.\n",
      "---\n",
      "Title: Advancing Healthcare Research & AI in Medicine - Google Health\n",
      "Link: https://health.google/health-research/\n",
      "Snippet: Our team of clinicians, researchers, and engineers are all working together to create new AI and discover opportunities to increase the availability and ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The search results have provided several useful links for further exploration regarding Google's latest AI research. These include Google's own research site, a blog that offers updates on Google's research, a news site about AI developments at Google, and specific pages about Google's work in areas like healthcare and human-computer interaction. To get a comprehensive understanding of the latest trends in Google's AI research, I need to explore these links in depth. Since this task requires extensive reading and summarizing, I'll delegate this task to my co-worker, the Writer, who is skilled in these areas.\n",
      "\n",
      "Action: Delegate work to co-worker\n",
      "Action Input: {\"task\": \"Read and summarize the key points from the provided links\", \"context\": \"We are trying to identify the latest trends in AI research by Google. I have found several potential sources of information. Please read through these and provide a summary of the key points. Here are the links: [http://research.google/, https://ai.google/discover/research/, http://research.google/blog/, https://www.artificialintelligence-news.com/categories/ai-companies/google/, https://labs.google/, https://blog.google/technology/research/google-ai-research-new-images-human-brain/, https://deepmind.google/research/publications/, https://pair.withgoogle.com/, https://health.google/health-research/].\", \"coworker\": \"Writer\"}\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt seems like a fairly complex task as there are multiple sources to evaluate and summarize. A good approach would be to visit each link one by one, extract key points, and then combine them into a single comprehensive summary. I will start with the first link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"http://research.google/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google Research - Explore Our Latest Research in Science and AI\n",
      "Link: http://research.google/\n",
      "Snippet: Discover Google Research. We publish research papers across a wide range of domains and share our latest developments in AI and science research.\n",
      "---\n",
      "Title: Google Scholar\n",
      "Link: https://scholar.google.com/\n",
      "Snippet: Google Scholar provides a simple way to broadly search for scholarly literature. Search across a wide variety of disciplines and sources: articles, theses, ...\n",
      "---\n",
      "Title: Research at Google\n",
      "Link: https://research.google.com/search.html?q=customer%20sentiment%20analysis\n",
      "Snippet: Research at Google · {{link.text}} · {{link.text}} · Home · Publications · People · Teams · Blog · Work at Google. More. Google Scholar · YouTube Tech Talks.\n",
      "---\n",
      "Title: Google User Experience Research - Discover How UX Research ...\n",
      "Link: https://userresearch.google.com/\n",
      "Snippet: We'd love to know about your Google user experience. Sign up to participate in UX research and influence Google products, whether you use them or not.\n",
      "---\n",
      "Title: Dataset Search\n",
      "Link: https://datasetsearch.research.google.com/\n",
      "Snippet: Learn more about Dataset Search.\n",
      "---\n",
      "Title: Big Picture: Google Visualization Research\n",
      "Link: https://research.google.com/bigpicture/\n",
      "Snippet: We explore how information visualization can make complex data accessible, useful, and even fun. Our focus is on ways to illuminate the data and algorithms ...\n",
      "---\n",
      "Title: Welcome To Colab - Colab - Google\n",
      "Link: https://colab.research.google.com/\n",
      "Snippet: Developing and training neural networks; Experimenting with TPUs; Disseminating AI research; Creating tutorials. To see sample Colab notebooks that demonstrate ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The first link leads to the main page of Google Research, where they publish research papers across various domains and share the latest developments in AI and science research. The information doesn't provide specific trends but it's a good starting point. Let's move on to the next link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"https://ai.google/discover/research/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Research - Google AI\n",
      "Link: https://ai.google/discover/research/\n",
      "Snippet: RESEARCH: Tackling the most challenging problems in computer science. Our teams aspire to make discoveries that positively impact society.\n",
      "---\n",
      "Title: PaLM 2 - Google AI\n",
      "Link: https://ai.google/discover/palm2/\n",
      "Snippet: ... Google's legacy of breakthrough research in machine learning and responsible AI. It excels at advanced reasoning tasks, including code and math ...\n",
      "---\n",
      "Title: Making AI helpful for everyone - Google AI – Google AI\n",
      "Link: https://ai.google/\n",
      "Snippet: Our AI innovations are built using our responsible AI practices and led by teams at Google DeepMind and Google Research. Learn more. Guided by principles ...\n",
      "---\n",
      "Title: Google Research - Explore Our Latest Research in Science and AI\n",
      "Link: http://research.google/\n",
      "Snippet: Discover Google Research. We publish research papers across a wide range of domains and share our latest developments in AI and science research.\n",
      "---\n",
      "Title: Blogs – Google AI\n",
      "Link: https://ai.google/discover/blogs/\n",
      "Snippet: Additional blogs to explore ; FOR Researchers. People & AI Research Blog ; For IT Leaders. Google Cloud Blog ; FOR BUSINESS LEADERS. Transform with Google Cloud ...\n",
      "---\n",
      "Title: Learn about our leading AI models - Google AI\n",
      "Link: https://ai.google/discover/our-models/\n",
      "Snippet: Discover the AI models behind our most impactful innovations, understand their capabilities, and find the right one when you're ready to build your own AI ...\n",
      "---\n",
      "Title: Google Science AI\n",
      "Link: https://ai.google/discover/scienceai/\n",
      "Snippet: Together, our aim is to enable scientific innovation for a better world. Explore how teams at Google are using AI to accelerate scientific discovery.\n",
      "---\n",
      "Title: Advancing Education Using Google AI\n",
      "Link: https://edu.google.com/why-google/ai-for-education/\n",
      "Snippet: Discover how AI technology and tools can be used for education to create personalized and enriched learning experiences.\n",
      "---\n",
      "Title: Google Generative AI\n",
      "Link: https://ai.google/discover/generativeai/\n",
      "Snippet: Explore how teams at Google are using Generative AI to create new experiences. Historically, AI was used to understand and recommend information. Now, ...\n",
      "---\n",
      "Title: AI & Machine Learning Products & Services | Google Cloud\n",
      "Link: https://cloud.google.com/products/ai\n",
      "Snippet: A single platform for data scientists and engineers to create, train, test, monitor, tune, and deploy ML and AI models. Choose from over 130 models in Vertex's ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The second link shares information about Google AI's research. They are tackling challenging problems in computer science with the aim to make positive societal impacts. There's also a mention of Google's legacy of breakthrough research in machine learning and responsible AI, implying a continued focus on these areas. Let's continue to the next link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"http://research.google/blog/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Blog – Google Research\n",
      "Link: http://research.google/blog/\n",
      "Snippet: The latest research from Google · Conferences & Events · Generative AI · Health & Bioscience · Machine Intelligence · Product · Quantum · Responsible AI ...\n",
      "---\n",
      "Title: AI in software engineering at Google: Progress and the path ahead\n",
      "Link: https://research.google/blog/ai-in-software-engineering-at-google-progress-and-the-path-ahead/\n",
      "Snippet: In this blog, we present our newest AI-powered improvements within the context of the continuing transformation of Google's internal software ...\n",
      "---\n",
      "Title: Research | Google Blog\n",
      "Link: https://blog.google/technology/research/\n",
      "Snippet: Research is a core part of our culture. Learn more about Google's latest breakthroughs.\n",
      "---\n",
      "Title: Blog - Google Research\n",
      "Link: http://blog.research.google/2022/?m=1\n",
      "Snippet: Google Research Blog. Google Research Blog. Google Research. Philosophy · Research Areas · Publications · People · Resources · Outreach · Careers · Blog. Search.\n",
      "---\n",
      "Title: Advances in private training for production on-device language ...\n",
      "Link: http://research.google/blog/advances-in-private-training-for-production-on-device-language-models/\n",
      "Snippet: In this blog we discuss how years of research advances now power the private training of Gboard LMs, since the proof-of-concept development of ...\n",
      "---\n",
      "Title: Social learning: Collaborative learning with large language models\n",
      "Link: http://research.google/blog/social-learning-collaborative-learning-with-large-language-models/\n",
      "Snippet: We outline a framework for social learning in which LLMs share knowledge with each other in a privacy-aware manner using natural language.\n",
      "---\n",
      "Title: Patchscopes: A unifying framework for inspecting hidden ...\n",
      "Link: http://research.google/blog/patchscopes-a-unifying-framework-for-inspecting-hidden-representations-of-language-models/\n",
      "Snippet: Avi Caciularu and Asma Ghandeharioun, Research Scientists, Google Research. Patchscopes is a new framework that aims to unify a variety of ...\n",
      "---\n",
      "Title: A decoder-only foundation model for time-series forecasting\n",
      "Link: http://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/\n",
      "Snippet: Careers · Blog. Search. Blog. A decoder-only foundation model for time-series forecasting. February 2, 2024. Posted by Rajat Sen and Yichen Zhou, Google ...\n",
      "---\n",
      "Title: Speed Matters - Google Research\n",
      "Link: http://research.google/blog/speed-matters/\n",
      "Snippet: At Google, we've gathered hard data to reinforce our intuition that \"speed matters\" on the Internet. Google runs experiments on the search ...\n",
      "---\n",
      "Title: Solving the minimum cut problem for undirected graphs\n",
      "Link: http://research.google/blog/solving-the-minimum-cut-problem-for-undirected-graphs/\n",
      "Snippet: Careers · Blog. Search. Blog. Solving the minimum cut problem for undirected graphs. April 16, 2024. Di Wang, Research Scientist, Google Research.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The third link is a blog from Google Research that provides updates on their latest projects. The blog covers a wide range of topics, including Generative AI, Health & Bioscience, Machine Intelligence, Product, Quantum, and Responsible AI. Some specific areas of research include AI in software engineering, private training for on-device language models, collaborative learning with large language models, and time-series forecasting. Next, I'll explore the fourth link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"https://www.artificialintelligence-news.com/categories/ai-companies/google/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Latest AI Developments at Google - AI News\n",
      "Link: https://www.artificialintelligence-news.com/categories/ai-companies/google/\n",
      "Snippet: Categories. Deep & Reinforcement Learning · Machine Learning · Robotics · Voice Recognition. AI News provides artificial intelligence news and jobs, industry ...\n",
      "---\n",
      "Title: AI News - Artificial Intelligence News\n",
      "Link: https://www.artificialintelligence-news.com/\n",
      "Snippet: Artificial Intelligence News provides the latest AI news and trends. Explore industry research and reports from the frontline of AI technology news.\n",
      "---\n",
      "Title: About AI News\n",
      "Link: https://www.artificialintelligence-news.com/about-us/\n",
      "Snippet: Categories. Deep & Reinforcement Learning · Machine Learning · Robotics · Voice Recognition. AI News provides artificial intelligence news and jobs, industry ...\n",
      "---\n",
      "Title: 76 Artificial Intelligence (AI) Companies to Know | Built In\n",
      "Link: https://builtin.com/artificial-intelligence/ai-companies-roundup\n",
      "Snippet: From Google and Amazon to Apple and Microsoft, every major tech company is dedicating resources to breakthroughs in artificial intelligence.\n",
      "---\n",
      "Title: How AI companies are beating Google, Apple and Amazon - YouTube\n",
      "Link: https://www.youtube.com/watch?v=5uBiI9m6hXQ\n",
      "Snippet: Stop data brokers from exposing your personal information. Go to my sponsor https://aura.com ...\n",
      "---\n",
      "Title: AI pioneers turn whistleblowers and demand safeguards\n",
      "Link: https://www.artificialintelligence-news.com/2024/06/06/ai-pioneers-turn-whistleblowers-demand-safeguards/\n",
      "Snippet: Categories. Deep & Reinforcement Learning · Machine Learning · Robotics · Voice Recognition. AI News provides artificial intelligence news and ...\n",
      "---\n",
      "Title: AI News\n",
      "Link: https://www.artificialintelligence-news.com/artificial-intelligence-news/\n",
      "Snippet: Categories. Deep & Reinforcement Learning · Machine Learning · Robotics · Voice Recognition. AI News provides artificial intelligence news and jobs, industry ...\n",
      "---\n",
      "Title: Artificial Intelligence Stocks: The 10 Best AI Companies | Investing\n",
      "Link: https://money.usnews.com/investing/articles/artificial-intelligence-stocks-the-10-best-ai-companies\n",
      "Snippet: AI stocks are having a moment. Here are 10 of the best AI companies on Wall Street.\n",
      "---\n",
      "Title: Latest Applications for AI - AI News\n",
      "Link: https://www.artificialintelligence-news.com/categories/ai-applications/\n",
      "Snippet: Categories. Deep & Reinforcement Learning · Machine Learning · Robotics · Voice Recognition. AI News provides artificial intelligence news and jobs, industry ...\n",
      "---\n",
      "Title: Artificial Intelligence News | AI Development News | Developer News\n",
      "Link: https://www.developer-tech.com/categories/developer-ai/\n",
      "Snippet: ... company's approach to integrating AI into ... Google continues AI push with new Gemini tools for developers ... Categories. API · Artificial Intelligence · Cloud ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The fourth link leads to a page on AI News that provides updates on the latest AI developments at Google. It doesn't provide specific details in the search results, but it indicates that the page covers various categories such as Deep & Reinforcement Learning, Machine Learning, Robotics, and Voice Recognition. This suggests that Google is active in these areas of AI research. Let's proceed to the fifth link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"https://labs.google/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google Labs\n",
      "Link: https://labs.google/\n",
      "Snippet: Labs.Google is Google's home for the latest AI tools, technology and discourse.\n",
      "---\n",
      "Title: Search Labs - Google Labs\n",
      "Link: https://labs.google.com/search\n",
      "Snippet: Welcome to Search Labs. Test new featuresDiscover AI and moreTell us what you ... What can we do to make Search Labs better? Share feedback. googlegoogle_labs.\n",
      "---\n",
      "Title: Try experiments in Search Labs - Google Labs\n",
      "Link: https://labs.google.com/search/install\n",
      "Snippet: Test early-stage Google Search experiments and share your feedback. Get started in Google Chrome on desktop or in the Google App on your phone.\n",
      "---\n",
      "Title: Try experiments in Search Labs - Computer - Google Help\n",
      "Link: https://support.google.com/websearch/answer/13572013?hl=en&co=GENIE.Platform%3DDesktop\n",
      "Snippet: Search Labs is a program for people to experiment with early-stage Google Search experiences and share feedback. If you're eligible and interested in Search ...\n",
      "---\n",
      "Title: Search Labs\n",
      "Link: https://search.google/ways-to-search/search-labs/\n",
      "Snippet: Try the latest AI experiments in Search and share your feedback directly with our team. Explore the latest experiments by tapping the icon in the Google app, ...\n",
      "---\n",
      "Title: Google Search Help\n",
      "Link: https://support.google.com/websearch/thread/226573083/unwanted-and-unsolicited-image-i-e-https-labs-google-com-search-experiments-source-ntp-appeare?hl=en\n",
      "Snippet: Unwanted and unsolicited image, i.e., https://labs.google.com/search/experiments?source=ntp, appeare. I did not solicit this image and ...\n",
      "---\n",
      "Title: Experiments with Google\n",
      "Link: https://experiments.withgoogle.com/\n",
      "Snippet: Since 2009, coders have created thousands of amazing experiments using Chrome, Android, AI, WebVR, AR and more. We're showcasing projects here, along with ...\n",
      "---\n",
      "Title: Labs.Google - Hacker News\n",
      "Link: https://news.ycombinator.com/item?id=38730107\n",
      "Snippet: We head to wait a long time but web technology is now finally able to recreate the flash websites of yore without using flash.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The fifth link is Google Labs, which is Google's home for the latest AI tools, technology, and discourse. It seems like a platform for testing early-stage Google technologies and experiments. It's a place where innovative ideas are tested and feedback is collected. Let's move on to the next link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"https://blog.google/technology/research/google-ai-research-new-images-human-brain/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google AI: New insights from 6 images of the human brain\n",
      "Link: https://blog.google/technology/research/google-ai-research-new-images-human-brain/\n",
      "Snippet: Google researchers and Harvard neuroscientists have worked together to reveal incredible images of the human brain.\n",
      "---\n",
      "Title: Blog – Google Research\n",
      "Link: http://research.google/blog/\n",
      "Snippet: The latest research from Google · Conferences & Events · Generative AI · Health & Bioscience · Machine Intelligence · Product · Quantum · Responsible AI ...\n",
      "---\n",
      "Title: Ten years of neuroscience at Google yields maps of human brain\n",
      "Link: http://research.google/blog/ten-years-of-neuroscience-at-google-yields-maps-of-human-brain/\n",
      "Snippet: Marking ten years of connectomics research at Google, we are releasing a publication in Science about a reconstruction at the synaptic level ...\n",
      "---\n",
      "Title: Full scan of 1 cubic millimeter of brain tissue took 1.4 petabytes of ...\n",
      "Link: https://www.reddit.com/r/IsaacArthur/comments/1crokfn/full_scan_of_1_cubic_millimeter_of_brain_tissue/\n",
      "Snippet: Full scan of 1 cubic millimeter of brain tissue took 1.4 petabytes of data, equivalent to 14,000 4K movies — Google's AI experts assist ...\n",
      "---\n",
      "Title: Research - Google AI\n",
      "Link: https://ai.google/discover/research/\n",
      "Snippet: RESEARCH: Tackling the most challenging problems in computer science. Our teams aspire to make discoveries that positively impact society.\n",
      "---\n",
      "Title: Project Starline: Google and HP partner on 2025 commercialization\n",
      "Link: https://blog.google/technology/research/google-project-starline-hp-partnership/\n",
      "Snippet: We are proud to partner with Google to bring this technology ... 6 incredible images of the human brain built with the help of Google's AI.\n",
      "---\n",
      "Title: google AI and harvard researchers release detailed images of ...\n",
      "Link: https://www.designboom.com/technology/google-ai-harvard-researchers-images-human-brain-3d-mapping-05-13-2024/\n",
      "Snippet: Researchers from Google and Harvard University have recently released a new set of detailed images of the human brain and its neural ...\n",
      "---\n",
      "Title: Google DeepMind and Isomorphic Labs introduce AlphaFold 3 AI ...\n",
      "Link: https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/\n",
      "Snippet: Our new AI model AlphaFold 3 can predict the structure and interactions of all life's molecules with unprecedented accuracy.\n",
      "---\n",
      "Title: Google DeepMind\n",
      "Link: https://deepmind.google/\n",
      "Snippet: Hear how AI can transform our world. Blog — Discover our latest AI breakthroughs, projects, and updates. Events — Meet our team and learn more about our ...\n",
      "---\n",
      "Title: Making AI helpful for everyone - Google AI – Google AI\n",
      "Link: https://ai.google/\n",
      "Snippet: At Google, we want to make AI helpful for everyone because we think that AI can meaningfully improve people's lives.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The sixth link is a specific blog post about Google's AI research on the human brain. Google researchers and Harvard neuroscientists have collaborated on this project. This indicates Google's interest in leveraging AI for advancements in neuroscience. Let's gather information from the seventh link now.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"https://deepmind.google/research/publications/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Publications - Google DeepMind\n",
      "Link: https://deepmind.google/research/publications/\n",
      "Snippet: Publications. Explore a selection of our recent research on some of the most complex and interesting challenges in AI.\n",
      "---\n",
      "Title: Publications - Google DeepMind\n",
      "Link: https://deepmind.google/research/publications/?page=2\n",
      "Snippet: Publications. Explore a selection of our recent research on some of the most complex and interesting challenges in AI. 157 publications Load ...\n",
      "---\n",
      "Title: Google DeepMind\n",
      "Link: https://deepmind.google/\n",
      "Snippet: Breakthrough AI system accurately predicts the 3D models of protein structures — and accelerates research in nearly every field of biology. Responsibility. We ...\n",
      "---\n",
      "Title: Publications - Google DeepMind\n",
      "Link: https://deepmind.google/research/publications/?q=reinforcement+learning&page=7\n",
      "Snippet: Explore a selection of our recent research on some of the most complex and interesting challenges in AI. 154 publications Load previous. Date ...\n",
      "---\n",
      "Title: Publications - Google DeepMind\n",
      "Link: https://deepmind.google/research/publications/?q=reinforcement+learning&page=6\n",
      "Snippet: Explore a selection of our recent research on some of the most complex and interesting challenges in AI. 153 publications Load previous. Date ...\n",
      "---\n",
      "Title: google-deepmind/deepmind-research - GitHub\n",
      "Link: https://github.com/google-deepmind/deepmind-research\n",
      "Snippet: This repository contains implementations and illustrative code to accompany DeepMind publications. Along with publishing papers to accompany research ...\n",
      "---\n",
      "Title: Google DeepMind's latest research at ICML 2023\n",
      "Link: https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/\n",
      "Snippet: Google DeepMind researchers are presenting more than 80 new papers at the 40th International Conference on Machine Learning (ICML 2023), ...\n",
      "---\n",
      "Title: Google Research - Explore Our Latest Research in Science and AI\n",
      "Link: http://research.google/\n",
      "Snippet: Discover Google Research. We publish research papers across a wide range of domains and share our latest developments in AI and science research.\n",
      "---\n",
      "Title: DeepMind's latest research at ICLR 2023\n",
      "Link: https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/\n",
      "Snippet: See the full list of DeepMind papers and schedule of events at ICLR 2023. ... research teams are presenting 29 papers ... About Google DeepMind ...\n",
      "---\n",
      "Title: Millions of new materials discovered with deep learning\n",
      "Link: https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/\n",
      "Snippet: We share the discovery of 2.2 million new crystals – equivalent to nearly 800 years' worth of knowledge. We introduce Graph Networks for ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The seventh link is Google DeepMind's page for their research publications. It showcases their recent research on some of the most complex and interesting challenges in AI. It indicates that DeepMind is actively engaged in cutting-edge AI research, including predicting the 3D models of protein structures, presenting over 80 new papers at the International Conference on Machine Learning, and discovering 2.2 million new crystals with deep learning. Now let's look at the eighth link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"https://pair.withgoogle.com/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: People + AI Research - Google\n",
      "Link: https://pair.withgoogle.com/\n",
      "Snippet: People + AI Research (PAIR) is a multidisciplinary team at Google that explores the human side of AI by doing fundamental research, building tools, creating ...\n",
      "---\n",
      "Title: People + AI Guidebook\n",
      "Link: https://pair.withgoogle.com/guidebook/\n",
      "Snippet: People + AI Guidebook. pair.withgoogle.com/guidebook. Published May 8 ... Based on a work at pair.withgoogle.com. Google Research · Google Design.\n",
      "---\n",
      "Title: People + AI Guidebook - Google Design - Medium\n",
      "Link: https://medium.com/google-design/https-medium-com-jessholbrook-people-ai-guidebook-41ec2ee5ec3f\n",
      "Snippet: https://pair.withgoogle.com. This Guidebook will help you build human-centered AI products. It will enable you to avoid common mistakes, ...\n",
      "---\n",
      "Title: PAIR - YouTube\n",
      "Link: https://www.youtube.com/channel/UCnnns-uu4yy9BXfYSPIX5AA\n",
      "Snippet: The People + AI Research (PAIR) initiative at Google advances the research and design of people-centric AI systems. We're interested in the full spectrum of ...\n",
      "---\n",
      "Title: Can someone explain Google PAIR to me like I'm five? - Reddit\n",
      "Link: https://www.reddit.com/r/programmatic/comments/yin9tx/can_someone_explain_google_pair_to_me_like_im_five/\n",
      "Snippet: Is PAIR really just a new protocol for targeting audiences across various ad exchanges in a cookie-less/clean-room environment?\n",
      "---\n",
      "Title: PAIR: the People + AI Research Initiative - The Keyword\n",
      "Link: https://blog.google/technology/ai/pair-people-ai-research-initiative/\n",
      "Snippet: Today we're announcing the People + AI Research initiative (PAIR) which brings together researchers across Google to study and redesign the ways ...\n",
      "---\n",
      "Title: Apache-2.0 license - GitHub\n",
      "Link: https://github.com/PAIR-code/ai-explorables\n",
      "Snippet: https://pair.withgoogle.com/explorables/. Contribute to PAIR-code/ai-explorables development by creating an account on GitHub.\n",
      "---\n",
      "Title: Can't Pair Google Messages : r/beeper - Reddit\n",
      "Link: https://www.reddit.com/r/beeper/comments/18nnjab/cant_pair_google_messages/\n",
      "Snippet: The short answer is.. Whatever device you're using say (Andriod w/ Google Messages) and then you're trying to login another device (Laptop, ...\n",
      "---\n",
      "Title: People + AI Research - Medium\n",
      "Link: https://medium.com/people-ai-research\n",
      "Snippet: ... Lucas Dixon. Meet the new co-leads of PAIR: Lucas Dixon and Michael Terry. Read more… 147. Go to the profile of People + AI Research @ Google.\n",
      "---\n",
      "Title: Unable to pair Google Messages with Google Account\n",
      "Link: https://support.google.com/messages/thread/272669556/unable-to-pair-google-messages-with-google-account?hl=en\n",
      "Snippet: Every time I open Google Messages, click the profile icon, then Device Pairing, I get “Can't pair with your Google Account right now.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The eighth link is about Google's People + AI Research (PAIR) initiative. PAIR is a multidisciplinary team within Google that explores the human side of AI, conducting fundamental research, building tools, and creating design resources. The focus on the human-centered aspect of AI is a noteworthy trend in Google's AI research. Next, I'll check the ninth link.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"https://health.google/health-research/\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Advancing Healthcare Research & AI in Medicine - Google Health\n",
      "Link: https://health.google/health-research/\n",
      "Snippet: Explore the healthcare technology advancements developed by our team of clinicians, researchers, and engineers to improve our understanding of health.\n",
      "---\n",
      "Title: Google Health research publications\n",
      "Link: https://health.google/health-research/publications/\n",
      "Snippet: Our health research publications allow us to share ideas and work collaboratively through comprehensive publications and associated blog posts.\n",
      "---\n",
      "Title: AI Imaging & Diagnostics - Google Health\n",
      "Link: https://health.google/health-research/imaging-and-diagnostics/\n",
      "Snippet: Our diagnostic imaging research aims to improve disease detection with AI. Advanced imaging and diagnostics may eventually help with treatment plans.\n",
      "---\n",
      "Title: Health - Google Research\n",
      "Link: https://research.google/teams/health/\n",
      "Snippet: We are working to create new machine learning tools and discover opportunities to increase the availability and accuracy of healthcare globally.\n",
      "---\n",
      "Title: What Is Google Health? - Google Health\n",
      "Link: https://health.google/\n",
      "Snippet: At Google Health, we're dedicated to improving the physical and mental health and patient care that women+ receive, through our research, product development, ...\n",
      "---\n",
      "Title: Participate in research with Google Health Studies\n",
      "Link: https://health.google/consumers/health-studies/\n",
      "Snippet: The Google Health Studies app lets you securely contribute to health research studies with leading institutions, right from your phone.\n",
      "---\n",
      "Title: Google is committed to health equity\n",
      "Link: https://health.google/health-equity/\n",
      "Snippet: Google Health, Google Cloud Platform, Fitbit, and Fitabase are partnering to advance health equity and mitigate health disparities. Researchers at academic ...\n",
      "---\n",
      "Title: The Value of Genomic Analysis - Google Health\n",
      "Link: https://health.google/health-research/genomics/\n",
      "Snippet: Discover how Google is using DeepVariant to improve the accuracy of genomic analysis, which identifies variants in DNA that indicate genetic disorders.\n",
      "---\n",
      "Title: Health Tech & Research Partners - Google Health\n",
      "Link: https://health.google/partners/\n",
      "Snippet: We've partnered with world-class clinical, public health and academic organizations to deploy transformative healthcare tools and services.\n",
      "---\n",
      "Title: Transforming Smartphone Sensors into Health Insights\n",
      "Link: https://health.google/health-research/mobile-sensing/\n",
      "Snippet: We are developing sensing technologies to detect vital health information that can work on smartphones around the world. By making health knowledge ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The ninth link is about Google Health's research. They are working on healthcare technology advancements to improve our understanding of health. Some areas of focus include diagnostic imaging research for disease detection, creating new machine learning tools for healthcare, genomics, and developing sensing technologies to detect vital health information. This shows Google's interest in leveraging AI for advancements in health and medicine. I have now gathered information from all the links. It's time to compile this into a comprehensive summary.\n",
      "\n",
      "Final Answer: \n",
      "Google's AI research spans a wide range of applications and domains. They publish research papers across various domains and share the latest developments in AI and science on Google Research. The focus of Google AI's research is on tackling challenging problems in computer science with the aim to make discoveries that positively impact society. Google Research's blog posts reveal that they are exploring a wide range of topics, including Generative AI, Health & Bioscience, Machine Intelligence, Product, Quantum, and Responsible AI. Google Labs serves as a platform for testing early-stage Google technologies and collecting feedback. Google researchers are also collaborating with Harvard neuroscientists to leverage AI for advancements in neuroscience. Google's DeepMind is actively engaged in cutting-edge AI research, including predicting the 3D models of protein structures, presenting over 80 new papers at the International Conference on Machine Learning, and discovering 2.2 million new crystals with deep learning. People + AI Research (PAIR) initiative focuses on the human-centered aspect of AI, exploring the human side of AI, conducting fundamental research, building tools, and creating design resources. Google Health is working on healthcare technology advancements to improve our understanding of health, including diagnostic imaging research for disease detection, creating new machine learning tools for healthcare, genomics, and developing sensing technologies to detect vital health information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[95m \n",
      "\n",
      "Google's AI research spans a wide range of applications and domains. They publish research papers across various domains and share the latest developments in AI and science on Google Research. The focus of Google AI's research is on tackling challenging problems in computer science with the aim to make discoveries that positively impact society. Google Research's blog posts reveal that they are exploring a wide range of topics, including Generative AI, Health & Bioscience, Machine Intelligence, Product, Quantum, and Responsible AI. Google Labs serves as a platform for testing early-stage Google technologies and collecting feedback. Google researchers are also collaborating with Harvard neuroscientists to leverage AI for advancements in neuroscience. Google's DeepMind is actively engaged in cutting-edge AI research, including predicting the 3D models of protein structures, presenting over 80 new papers at the International Conference on Machine Learning, and discovering 2.2 million new crystals with deep learning. People + AI Research (PAIR) initiative focuses on the human-centered aspect of AI, exploring the human side of AI, conducting fundamental research, building tools, and creating design resources. Google Health is working on healthcare technology advancements to improve our understanding of health, including diagnostic imaging research for disease detection, creating new machine learning tools for healthcare, genomics, and developing sensing technologies to detect vital health information.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The observation from the Writer provides a comprehensive summary of the latest trends in AI research by Google. It's clear that Google is involved in a wide variety of AI applications, including Generative AI, Machine Intelligence, Quantum, and Responsible AI. They are also making significant strides in healthcare technology advancements and human-centered AI research. I will now craft a three-paragraph report, detailing the key points, market opportunities, and potential risks.\n",
      "\n",
      "Action: Delegate work to co-worker\n",
      "Action Input: {\"task\": \"Craft a comprehensive three-paragraph report\", \"context\": \"Based on the summaries you provided, we know that Google's AI research spans a wide range of applications and domains. They are exploring Generative AI, Machine Intelligence, Quantum, and Responsible AI. They are also making significant strides in healthcare technology advancements and human-centered AI research. Please create a report that details these key points, the market opportunities they present, and any potential risks. Here are some points to consider: \\n- Generative AI, Machine Intelligence, Quantum, and Responsible AI research and their applications\\n- Collaborations with Harvard neuroscientists for advancements in neuroscience\\n- DeepMind's cutting-edge AI research, including predicting the 3D models of protein structures and discovering new crystals with deep learning\\n- The human-centered aspect of AI explored by the People + AI Research (PAIR) initiative\\n- Healthcare technology advancements by Google Health, including diagnostic imaging research for disease detection, creating new machine learning tools for healthcare, genomics, and developing sensing technologies to detect vital health information\", \"coworker\": \"Writer\"}\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo craft a comprehensive report, I need to gather more specific and recent information about these key points: Generative AI, Machine Intelligence, Quantum, Responsible AI, Google's collaborations with Harvard, DeepMind's AI research, the PAIR initiative, and Google Health's advancements.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"Google AI research Generative AI applications\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google Generative AI\n",
      "Link: https://ai.google/discover/generativeai/\n",
      "Snippet: Empowering businesses and governments to build generative AI applications quickly, efficiently, and responsibly - armed with the best of Google's research and ...\n",
      "---\n",
      "Title: Generative AI | Google Cloud\n",
      "Link: https://cloud.google.com/ai/generative-ai\n",
      "Snippet: Bring generative AI to real-world experiences quickly, efficiently, and responsibly, powered by Google's most advanced technology and models including ...\n",
      "---\n",
      "Title: Generative AI Examples | Google Cloud\n",
      "Link: https://cloud.google.com/use-cases/generative-ai\n",
      "Snippet: Generative AI is a category of artificial intelligence that can create new text, images, video, audio, or code. Learn how it works with Google Cloud.\n",
      "---\n",
      "Title: Making AI helpful for everyone - Google AI – Google AI\n",
      "Link: https://ai.google/\n",
      "Snippet: A development platform for building and scaling generative AI applications. ... Our AI innovations are built using our responsible AI practices and led by teams ...\n",
      "---\n",
      "Title: Scientists' Perspectives on the Potential for Generative AI in their ...\n",
      "Link: https://research.google/pubs/scientists-perspectives-on-the-potential-for-generative-ai-in-their-fields/\n",
      "Snippet: There is potential for Generative AI to have a substantive impact on the methods and pace of discovery for a range of scientific disciplines. ... In addition to ...\n",
      "---\n",
      "Title: Announcing new generative AI experiences in Google Workspace\n",
      "Link: https://workspace.google.com/blog/product-announcements/generative-ai\n",
      "Snippet: Google Cloud announces generative AI support in Vertex AI and Generative AI App Builder, helping businesses and governments build gen apps.\n",
      "---\n",
      "Title: Google I/O 2024: New generative AI experiences in Search\n",
      "Link: https://blog.google/products/search/generative-ai-google-search-may-2024/\n",
      "Snippet: We're bringing AI Overviews to everyone in the U.S. and adding new gen AI experiences to take more of the legwork out of searching.\n",
      "---\n",
      "Title: Use generative AI to research documents in Pinpoint - Google Help\n",
      "Link: https://support.google.com/pinpoint/answer/14338615?hl=en\n",
      "Snippet: Research your collection with generative AI. In the right-hand panel of a collection, you can ask research questions and receive AI-powered answers. Scroll in ...\n",
      "---\n",
      "Title: PaLM 2 - Google AI\n",
      "Link: https://ai.google/discover/palm2/\n",
      "Snippet: PaLM 2 is powering generative AI features like email summarization in Gmail and brainstorming and rewriting in Docs.\n",
      "---\n",
      "Title: Understanding Google Generative AI: Applications, Tools, Models ...\n",
      "Link: https://medium.com/@sabine_vdl/understanding-google-generative-ai-applications-tools-models-and-use-cases-735cf4b19636\n",
      "Snippet: Generative AI refers to the application of Artificial Intelligence in creating new content such as text, images, music and videos using natural ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The search results have provided valuable information about Google's Generative AI. It seems that Google is using this technology in a variety of applications, including in real-world experiences, in Google Workspace, and even in Google Search. Now, I should gather information about the next key point: Machine Intelligence.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"Google AI research Machine Intelligence applications\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Machine Intelligence - Google Research\n",
      "Link: https://research.google/research-areas/machine-intelligence/\n",
      "Snippet: Google is at the forefront of innovation in Machine Intelligence, with active research exploring virtually all aspects of machine learning, including deep ...\n",
      "---\n",
      "Title: Applications of artificial intelligence (AI) | Google Cloud\n",
      "Link: https://cloud.google.com/discover/ai-applications\n",
      "Snippet: AI is utilized in different industries such as agriculture and education. Learn about AI applications with Google Cloud.\n",
      "---\n",
      "Title: Research - Google AI\n",
      "Link: https://ai.google/discover/research/\n",
      "Snippet: We regularly publish in academic journals, release projects as open source, and apply research to Google products to benefit users at scale. Learn more about ...\n",
      "---\n",
      "Title: AI & Machine Learning Products & Services | Google Cloud\n",
      "Link: https://cloud.google.com/products/ai\n",
      "Snippet: Innovate, optimize and amplify your SaaS applications using Google's data and machine learning solutions such as BigQuery, Looker, Spanner and Vertex AI.\n",
      "---\n",
      "Title: Google Research - Explore Our Latest Research in Science and AI\n",
      "Link: http://research.google/\n",
      "Snippet: Discover Google Research. We publish research papers across a wide range of domains and share our latest developments in AI and science research.\n",
      "---\n",
      "Title: Making AI helpful for everyone - Google AI – Google AI\n",
      "Link: https://ai.google/\n",
      "Snippet: At Google, we want to make AI helpful for everyone because we think that AI can meaningfully improve people's lives.\n",
      "---\n",
      "Title: People + AI Research - Google\n",
      "Link: https://pair.withgoogle.com/\n",
      "Snippet: We believe that for machine learning to achieve ... A friendly, practical guide that lays out some best practices for creating useful, responsible AI applications ...\n",
      "---\n",
      "Title: Google's Artificial Intelligence And Machine Learning Research ...\n",
      "Link: https://www.forbes.com/sites/jonyounger/2019/01/16/googles-ai-and-ml-research-priorities-freelancers-take-note/\n",
      "Snippet: Without doubt, artificial intelligence and machine learning are major areas of innovation for the greater tech community.\n",
      "---\n",
      "Title: Advancing Healthcare Research & AI in Medicine - Google Health\n",
      "Link: https://health.google/health-research/\n",
      "Snippet: Explore the healthcare technology advancements developed by our team of clinicians, researchers, and engineers to improve our understanding of health.\n",
      "---\n",
      "Title: Top 15 AI projects powering Google products in 2024\n",
      "Link: https://research.aimultiple.com/ai-is-already-at-the-heart-of-google/\n",
      "Snippet: From smartphone assistants to image recognition and translation, a myriad of AI functionality hides within google apps that you daily use. We ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The search results indicate that Google's Machine Intelligence research is extensive and is integrated into a variety of applications. It seems that Google is using Machine Intelligence to innovate, optimize, and amplify its services. Now, it's time to look into Google's research and applications in the field of Quantum Computing.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"Google AI research Quantum applications\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google Quantum AI\n",
      "Link: https://quantumai.google/\n",
      "Snippet: XPRIZE Quantum Applications | Google Quantum AI is a 3-year, $5M global competition designed to advance the field of quantum algorithms towards pro-society real ...\n",
      "---\n",
      "Title: Research Publications | Google Quantum AI\n",
      "Link: https://quantumai.google/research\n",
      "Snippet: Google Quantum AI is advancing the state of the art in quantum computing and developing the hardware and software tools to operate beyond classical ...\n",
      "---\n",
      "Title: Quantum Computing - Google Research\n",
      "Link: https://research.google/research-areas/quantum-computing/\n",
      "Snippet: Quantum Computing is the design of hardware and software that replaces Boolean logic by quantum law at the algorithmic level. For certain computations such as ...\n",
      "---\n",
      "Title: Google, GESDA and XPRIZE launch new competition in Quantum ...\n",
      "Link: https://blog.google/technology/research/google-gesda-and-xprize-launch-new-competition-in-quantum-applications/\n",
      "Snippet: XPRIZE Quantum Applications is designed to reward research contributions which most advance the field of quantum algorithms towards real-world ...\n",
      "---\n",
      "Title: Google, XPRIZE Launch $5M Quantum Application Challenge\n",
      "Link: https://www.hpcwire.com/2024/03/04/google-xprize-launch-5m-quantum-application-challenge/\n",
      "Snippet: Google Quantum AI, the XPRIZE Foundation, and the Geneva Science and Diplomacy Anticipator (GESDA) Foundation have announced a 3-year, $5 ...\n",
      "---\n",
      "Title: Google Quantum AI Team Demystifies Quantum Computing & Its ...\n",
      "Link: https://thequantuminsider.com/2024/06/07/google-quantum-ai-team-demystifies-quantum-computing-its-future-potential/\n",
      "Snippet: The Google Quantum AI team is committed to pushing the boundaries of quantum computing to tackle complex problems that classical computers can't ...\n",
      "---\n",
      "Title: [PDF] Our focused and responsible approach to quantum computing\n",
      "Link: https://ai.google/static/documents/approach-quantum-computing.pdf\n",
      "Snippet: Google Quantum AI aims to build this computer. Our roadmap is shown below, and includes six technical milestones towards top quality quantum computing hardware ...\n",
      "---\n",
      "Title: Google Launches $5M Quest for Real-World Quantum Applications\n",
      "Link: https://www.iotworldtoday.com/quantum/google-launches-5m-quest-for-real-world-quantum-applications\n",
      "Snippet: Google Quantum AI and Google.org, the charitable arm of Google, have launched a three-year, $5 million global competition to find quantum computing ...\n",
      "---\n",
      "Title: Overview | XPRIZE Quantum Applications\n",
      "Link: https://www.xprize.org/prizes/qc-apps\n",
      "Snippet: This prize brings together XPRIZE's expertise in designing, launching and executing large-scale competitions, Google Quantum AI's extensive ...\n",
      "---\n",
      "Title: Google's Quantum Computing Technology in 2024 Review\n",
      "Link: https://thequantuminsider.com/2023/05/08/google-quantum-computing/\n",
      "Snippet: Quantum algorithms and applications can also be built on Google's cloud-based quantum computing platform, the Google Quantum AI (QAI) platform.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The search results indicate that Google is heavily invested in Quantum Computing. It seems they are advancing the field of quantum algorithms and have even launched a global competition for real-world quantum applications. Now, I need to find information about Google's research and principles in the field of Responsible AI.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"Google AI research Responsible AI\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Responsible AI Practices - Google AI\n",
      "Link: https://ai.google/responsibility/responsible-ai-practices/\n",
      "Snippet: Responsible AI practices ; Fairness · Design your model using concrete goals for fairness and inclusion · Use representative datasets to train and test your model.\n",
      "---\n",
      "Title: Responsible AI - Google Research\n",
      "Link: https://research.google/teams/responsible-ai/\n",
      "Snippet: Develop machine learning methodologies that represent AI at its best (responsible, fair, transparent, robust, and inclusive), and apply them in the real world.\n",
      "---\n",
      "Title: Responsible AI | Google Cloud\n",
      "Link: https://cloud.google.com/responsible-ai\n",
      "Snippet: Responsible AI tools are an increasingly effective way to inspect and understand AI models. We're building resources like Explainable AI, Model Cards, and the ...\n",
      "---\n",
      "Title: Responsible AI - Google Research\n",
      "Link: https://research.google/research-areas/responsible-ai/\n",
      "Snippet: We examine and shape emerging AI models, systems, and datasets used in research, development, and practice. This research uncovers foundational insights and ...\n",
      "---\n",
      "Title: Google AI Principles\n",
      "Link: https://ai.google/responsibility/principles/\n",
      "Snippet: Google AI is committed to developing and using artificial intelligence responsibly. Our AI Principles provide a guiding framework for our work, ...\n",
      "---\n",
      "Title: Introduction to Responsible AI | Machine Learning\n",
      "Link: https://developers.google.com/machine-learning/resources/intro-responsible-ai\n",
      "Snippet: Responsible AI considers the societal impact of the development and scale of these technologies, including potential harms and benefits. The AI ...\n",
      "---\n",
      "Title: More ways Google is delivering on its responsible AI commitment\n",
      "Link: https://blog.google/technology/ai/google-responsible-ai-commitment-update/\n",
      "Snippet: Today we're announcing new AI safeguards to protect against misuse and new tools that use AI to make learning more engaging and accessible.\n",
      "---\n",
      "Title: Google Splits Up a Key AI Ethics Watchdog - WIRED\n",
      "Link: https://www.wired.com/story/google-splits-up-responsible-innovation-ai-team/\n",
      "Snippet: “If implemented properly, Responsible AI makes products better by uncovering and working to reduce the harm that unfair bias can cause, ...\n",
      "---\n",
      "Title: At I/O, Google Talks Up 'Responsible AI.' What's That All About?\n",
      "Link: https://www.cnet.com/tech/services-and-software/at-io-google-talks-up-responsible-ai-whats-that-all-about/\n",
      "Snippet: In the keynote presentation, Google outlined its approach to responsible AI, which includes a combination of automated and human resources. \"We' ...\n",
      "---\n",
      "Title: Google AI Review Process\n",
      "Link: https://ai.google/responsibility/ai-governance-operations/\n",
      "Snippet: RESPONSIBILITY: AI Governance reviews and operations. We assess proposals for new AI research and applications for alignment with our Principles.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The search results provide a wealth of information about Google's Responsible AI research. It's clear that Google is committed to developing AI responsibly, with dedicated tools, methodologies, and principles to guide this work. I have gathered key information about Generative AI, Machine Intelligence, Quantum Computing, and Responsible AI. Now, I need to gather information about Google's collaborations with Harvard, DeepMind's AI research, the PAIR initiative, and Google Health's advancements.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"Google AI research collaboration with Harvard neuroscientists\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google AI: New insights from 6 images of the human brain\n",
      "Link: https://blog.google/technology/research/google-ai-research-new-images-human-brain/\n",
      "Snippet: Google researchers and Harvard neuroscientists have worked together to reveal incredible images of the human brain.\n",
      "---\n",
      "Title: Epic science inside a cubic millimeter of brain - Harvard Gazette\n",
      "Link: https://news.harvard.edu/gazette/story/2024/05/the-brain-as-weve-never-seen-it/\n",
      "Snippet: Published in Science, the study is the latest development in a nearly 10-year collaboration with scientists at Google Research, combining ...\n",
      "---\n",
      "Title: Harvard/Google Use AI to Help Produce Astonishing 3D Map of ...\n",
      "Link: https://www.hpcwire.com/2024/05/10/harvard-google-use-ai-to-help-produce-astonishing-3d-map-of-brain-tissue/\n",
      "Snippet: Harvard/Google Use AI to Help Produce Astonishing 3D Map of Brain Tissue · Although LLMs are getting all the notice lately, AI techniques of many ...\n",
      "---\n",
      "Title: Google and Harvard unveil most detailed ever map of human brain\n",
      "Link: https://www.cnn.com/2024/05/15/world/human-brain-map-harvard-google-scn/index.html\n",
      "Snippet: Working from a sliver of tissue no bigger than a grain of rice, researchers have built an astoundingly complex map of the human brain.\n",
      "---\n",
      "Title: Ten years of neuroscience at Google yields maps of human brain\n",
      "Link: http://research.google/blog/ten-years-of-neuroscience-at-google-yields-maps-of-human-brain/\n",
      "Snippet: Through collaborations with researchers at the Howard Hughes Medical Institute, Harvard University, and Max Planck Institute we have also ...\n",
      "---\n",
      "Title: Google and Harvard researchers map fragment of human brain\n",
      "Link: https://www.htworld.co.uk/news/research-news/google-and-harvard-researchers-map-fragment-of-human-brain/\n",
      "Snippet: Researchers at Harvard University and Google have co-created the largest synaptic-resolution, 3D reconstruction of a piece of human brain to ...\n",
      "---\n",
      "Title: Google and Harvard Map a Tiny Piece of the Human Brain With ...\n",
      "Link: https://singularityhub.com/2024/05/13/google-and-harvard-map-a-tiny-piece-of-the-human-brain-with-extreme-precision/\n",
      "Snippet: Aided by machine learning tools from Google Research, the Harvard team traced neurons, blood vessels, and other brain cells at nanoscale levels.\n",
      "---\n",
      "Title: New 3D map charted with Google AI reveals 'mysterious but ...\n",
      "Link: https://www.livescience.com/health/neuroscience/new-3d-map-charted-with-google-ai-reveals-mysterious-but-beautiful-slice-of-human-brain\n",
      "Snippet: Harvard and Google researchers have collaborated to map a tiny fragment of an adult human brain in unprecedented detail.\n",
      "---\n",
      "Title: Mind-Blowing 3D Brain Map! Google AI & Harvard Just ... - YouTube\n",
      "Link: https://www.youtube.com/watch?v=W6jPB1DdRyE\n",
      "Snippet: Join me as we dive into a groundbreaking achievement in neuroscience! Google AI and ...\n",
      "---\n",
      "Title: Harvard and Google Neuroscience Breakthrough - SciTechDaily\n",
      "Link: https://scitechdaily.com/harvard-and-google-neuroscience-breakthrough-intricately-detailed-1400-terabyte-3d-brain-map/\n",
      "Snippet: A collaborative effort between Harvard and Google has led to a breakthrough in brain science, producing an extensive 3D map of a tiny ...\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The search results show that Google has collaborated with Harvard neuroscientists to reveal incredible images of the human brain. They used AI to help produce a detailed 3D map of brain tissue, an achievement which required machine learning tools from Google Research. Now, I will gather information about DeepMind's AI research.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"DeepMind AI research\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Google DeepMind\n",
      "Link: https://deepmind.google/\n",
      "Snippet: Artificial intelligence could be one of humanity's most useful inventions. We research and build safe artificial intelligence systems.\n",
      "---\n",
      "Title: Google DeepMind - Wikipedia\n",
      "Link: https://en.wikipedia.org/wiki/Google_DeepMind\n",
      "Snippet: Google DeepMind Technologies Limited is a British-American artificial intelligence research laboratory which serves as a subsidiary of Google.\n",
      "---\n",
      "Title: Google DeepMind: What It Does, How AGI Goal Differs From OpenAI\n",
      "Link: https://www.businessinsider.com/google-deepmind\n",
      "Snippet: DeepMind is Google's AI research hub focused on building artificial general intelligence. DeepMind has been applied to real-world problems ...\n",
      "---\n",
      "Title: Google DeepMind - YouTube\n",
      "Link: https://www.youtube.com/@Google_DeepMind\n",
      "Snippet: Inside Google DeepMind. We live in an exciting time when AI research and technology are delivering extraordinary advances. In the coming years, AI — and ...\n",
      "---\n",
      "Title: Google consolidates its DeepMind and Research teams amid AI push\n",
      "Link: https://www.reuters.com/technology/google-consolidates-its-deepmind-research-teams-amid-ai-push-2024-04-18/\n",
      "Snippet: The search engine giant had merged its research units Google Brain and DeepMind a year back to sharpen its focus on AI development and get ahead ...\n",
      "---\n",
      "Title: Materials-predicting AI from DeepMind could revolutionize ... - Science\n",
      "Link: https://www.science.org/content/article/materials-predicting-ai-deepmind-could-revolutionize-electronics-batteries-and-solar\n",
      "Snippet: Last month, they described an AI algorithm that runs on laptops and can predict the weather as accurately as large, supercomputer-driven models.\n",
      "---\n",
      "Title: Google consolidates AI-focused DeepMind, Research teams\n",
      "Link: https://www.foxbusiness.com/technology/google-consolidates-ai-focused-deepmind-research-teams\n",
      "Snippet: Google DeepMind was created last year through the merger of the Google Brain team with DeepMind and other researchers focused on AI systems.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The search results show that DeepMind, a subsidiary of Google, is a hub for AI research. Their focus is on building artificial general intelligence and applying it to real-world problems. Now, I will gather information about the People + AI Research (PAIR) initiative.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"People + AI Research initiative\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: People + AI Research\n",
      "Link: https://pair.withgoogle.com/\n",
      "Snippet: We are ResearchersArtists. People + AI Research (PAIR) is a multidisciplinary team at Google that explores the human side of AI by doing fundamental research ...\n",
      "---\n",
      "Title: PAIR: the People + AI Research Initiative - The Keyword\n",
      "Link: https://blog.google/technology/ai/pair-people-ai-research-initiative/\n",
      "Snippet: The goal of PAIR is to focus on the \"human side\" of AI: the relationship between users and technology, the new applications it enables, and how ...\n",
      "---\n",
      "Title: Responsible AI at Google Research: PAIR\n",
      "Link: http://research.google/blog/responsible-ai-at-google-research-pair/\n",
      "Snippet: PAIR (People + AI Research) first launched in 2017 with the belief that “AI can go much further — and be more useful to all of us — if we ...\n",
      "---\n",
      "Title: Google's new People+AI Research effort is exactly what AI needs\n",
      "Link: https://medium.com/architecht/googles-new-people-ai-research-effort-is-exactly-what-ai-needs-8fe18d99010b\n",
      "Snippet: Google announced an effort called People + AI Research that's focused on studying and improving the ways that people, from researchers to ...\n",
      "---\n",
      "Title: A New Google Project Sets Out to Solve Artificial Stupidity - WIRED\n",
      "Link: https://www.wired.com/story/google-artificial-intelligence-people-ai-research/\n",
      "Snippet: PAIR, for People + AI Research initiative, was announced today and will be led by two experts in data visualization, Fernanda Viégas and Martin ...\n",
      "---\n",
      "Title: Playing with AI Fairness - People + AI Research\n",
      "Link: https://pair-code.github.io/what-if-tool/ai-fairness.html\n",
      "Snippet: Researchers and designers at Google's PAIR (People and AI Research) initiative created the What-If visualization tool as a pragmatic resource for developers ...\n",
      "---\n",
      "Title: People + AI Research (PAIR) - Boston Global Forum\n",
      "Link: https://bostonglobalforum.org/news/people-ai-research-pair/\n",
      "Snippet: The PAIR project is an initiative of Google to research about AI where human input plays an early role in the learning process of an AI ...\n",
      "---\n",
      "Title: Google starts researching design for artificial intelligence systems\n",
      "Link: https://www.cnbc.com/2017/07/10/google-starts-researching-design-for-artificial-intelligence-systems.html\n",
      "Snippet: The research initiative will involve collaborations with people in multiple Google product groups, as well as professors from Harvard and MIT.\n",
      "---\n",
      "Title: Google's People + AI Research Initiative Presents deeplearn.js\n",
      "Link: https://tisch.nyu.edu/itp/events/fall-2017/google-people---ai-research-initiative-presents-deeplearn-js\n",
      "Snippet: Google stops by ITP to present deeplearn.js, Google's new open-source javascript machine learning library.\n",
      "---\n",
      "Title: Google Wants to Build a More 'Human' A.I. | Dice.com Career Advice\n",
      "Link: https://www.dice.com/career-advice/google-wants-build-human-ai\n",
      "Snippet: Google wants to start building artificial intelligence with “people in mind,\" via a new research initiative and some open-source tools.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[91m \n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}.\n",
      " Tool Delegate work to co-worker accepts these inputs: Delegate work to co-worker(task: str, context: str, coworker: Optional[str] = None, **kwargs) - Delegate a specific task to one of the following co-workers: [Writer]\n",
      "The input to this tool should be the co-worker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them.\n",
      "\u001b[00m\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Starting the task execution process with enhanced feedback\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/crewai/crew.py:264\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 264\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    266\u001b[0m     result, manager_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()  \u001b[38;5;66;03m# type: ignore # Unpacking a string is disallowed\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/crewai/crew.py:305\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_log_file:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_handler\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    302\u001b[0m         agent\u001b[38;5;241m=\u001b[39mrole, task\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mdescription, status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[0;32m--> 305\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39masync_execution:\n\u001b[1;32m    307\u001b[0m     task_output \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/crewai/task.py:183\u001b[0m, in \u001b[0;36mTask.execute\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/crewai/task.py:192\u001b[0m, in \u001b[0;36mTask._execute\u001b[0;34m(self, agent, task, context, tools)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent, task, context, tools):\n\u001b[0;32m--> 192\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     exported_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    201\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[1;32m    202\u001b[0m         exported_output\u001b[38;5;241m=\u001b[39mexported_output,\n\u001b[1;32m    203\u001b[0m         raw_output\u001b[38;5;241m=\u001b[39mresult,\n\u001b[1;32m    204\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/crewai/agent.py:236\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_description \u001b[38;5;241m=\u001b[39m render_text_description(parsed_tools)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__tools_names(parsed_tools)\n\u001b[0;32m--> 236\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rpm:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller\u001b[38;5;241m.\u001b[39mstop_rpm_counter()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/crewai/agents/executor.py:128\u001b[0m, in \u001b[0;36mCrewAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations, time_elapsed):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit():\n\u001b[0;32m--> 128\u001b[0m         next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_callback:\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_callback(next_step_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         [\n\u001b[1;32m   1139\u001b[0m             a\n\u001b[1;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1142\u001b[0m                 color_mapping,\n\u001b[1;32m   1143\u001b[0m                 inputs,\n\u001b[1;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1145\u001b[0m                 run_manager,\n\u001b[1;32m   1146\u001b[0m             )\n\u001b[1;32m   1147\u001b[0m         ]\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         [\n\u001b[1;32m   1139\u001b[0m             a\n\u001b[1;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1142\u001b[0m                 color_mapping,\n\u001b[1;32m   1143\u001b[0m                 inputs,\n\u001b[1;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1145\u001b[0m                 run_manager,\n\u001b[1;32m   1146\u001b[0m             )\n\u001b[1;32m   1147\u001b[0m         ]\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/crewai/agents/executor.py:192\u001b[0m, in \u001b[0;36mCrewAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    189\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore #  Incompatible types in assignment (expression has type \"AgentAction | AgentFinish | list[AgentAction]\", variable has type \"AgentAction\")\u001b[39;49;00m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py:397\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m             final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:2875\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2869\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2871\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   2872\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2874\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2875\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:2862\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2859\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2860\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2863\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2864\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   2865\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2866\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:1881\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1880\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1881\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1882\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1883\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:2826\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2818\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   2819\u001b[0m         final_pipeline,\n\u001b[1;32m   2820\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2823\u001b[0m         ),\n\u001b[1;32m   2824\u001b[0m     )\n\u001b[0;32m-> 2826\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2827\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:1282\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m final: Input\n\u001b[1;32m   1280\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ichunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m# The default implementation of transform is to buffer input and\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;66;03m# then call stream.\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;66;03m# It'll attempt to gather all input into a single chunk using\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# the `+` operator.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;66;03m# If the input is not addable, then we'll assume that we can\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;66;03m# only operate on the last chunk,\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;66;03m# and we'll iterate until we get to the last chunk.\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1291\u001b[0m         final \u001b[38;5;241m=\u001b[39m ichunk\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:4736\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   4731\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4732\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   4733\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4734\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4735\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 4736\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   4737\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4738\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4739\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   4740\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:1300\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1300\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:249\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    243\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    244\u001b[0m         e,\n\u001b[1;32m    245\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    246\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    247\u001b[0m         ),\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:229\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m generation: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m             chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_manager\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:408\u001b[0m, in \u001b[0;36mChatOpenAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    407\u001b[0m default_chunk_class \u001b[38;5;241m=\u001b[39m AIMessageChunk\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    410\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}"
     ]
    }
   ],
   "source": [
    "# Starting the task execution process with enhanced feedback\n",
    "result = crew.kickoff(inputs={'topic': topic})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7fcf3-0211-4649-ab67-307c9121b69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f0868-7089-4c33-aead-5f1b311d9268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
