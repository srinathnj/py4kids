{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this chapter is best to use [databricks community cluster](https://community.cloud.databricks.com) to practise\n",
    "\n",
    "see `../SparkSQL.sql`  and `../SparkSQL.html`\n",
    "\n",
    "\n",
    "one can use `spark-sql` CLI to enter `SQL` command directly\n",
    "\n",
    "\n",
    "\n",
    "- [Table Types in Spark: External or Managed?](http://www.gatorsmile.io/table-types-in-spark-external-or-managed/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"chapter-10-data-src\")\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n",
    "\n",
    "import os\n",
    "SPARK_BOOK_DATA_PATH = os.environ['SPARK_BOOK_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.207:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>chapter-10-data-src</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f586c8bc0a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = SPARK_BOOK_DATA_PATH + \"/data/flight-data/json/2015-summary.json\"\n",
    "\n",
    "spark.read.json(file_path)\\\n",
    "  .createOrReplaceTempView(\"flight_data\") # DF => SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wengong/spark_data//data/flight-data/json/2015-summary.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count)\n",
    "FROM flight_data GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")\\\n",
    "  .where(\"DEST_COUNTRY_NAME like 'S%'\")\\\n",
    "  .where(\"`sum(count)` > 10\")\n",
    "# SQL => DF\n",
    "\n",
    "\n",
    "# COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|   DEST_COUNTRY_NAME|sum(count)|\n",
      "+--------------------+----------+\n",
      "|             Senegal|        40|\n",
      "|              Sweden|       118|\n",
      "|               Spain|       420|\n",
      "|    Saint Barthelemy|        39|\n",
      "|Saint Kitts and N...|       139|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|           default|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_database()\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+\n",
      "|database|          tableName|isTemporary|\n",
      "+--------+-------------------+-----------+\n",
      "| default|            flights|      false|\n",
      "| default|        flights_csv|      false|\n",
      "| default|flights_from_select|      false|\n",
      "| default|       hive_flights|      false|\n",
      "| default|     hive_flights_2|      false|\n",
      "| default|      just_usa_view|      false|\n",
      "| default|partitioned_flights|      false|\n",
      "|        |        flight_data|       true|\n",
      "+--------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table hive_flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table hive_flights_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE flights (\n",
    "  DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "USING JSON OPTIONS (path '/home/wengong/spark_data//data/flight-data/json/2015-summary.json')\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select * from flights limit 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_stmt = f\"\"\"CREATE TABLE flights_csv (\n",
    "  DEST_COUNTRY_NAME STRING,\n",
    "  ORIGIN_COUNTRY_NAME STRING COMMENT \"remember, the US will be most prevalent\",\n",
    "  count LONG)\n",
    "USING csv OPTIONS (header true, path '{SPARK_BOOK_DATA_PATH}data/flight-data/csv/2015-summary.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE flights_csv (\\n  DEST_COUNTRY_NAME STRING,\\n  ORIGIN_COUNTRY_NAME STRING COMMENT \"remember, the US will be most prevalent\",\\n  count LONG)\\nUSING csv OPTIONS (header true, path \\'/home/wengong/spark_data/data/flight-data/csv/2015-summary.csv\\')\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql_stmt).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE if not exists flights_from_select USING parquet AS SELECT * FROM flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE if not exists flights_from_select2 USING parquet AS SELECT * FROM flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE partitioned_flights USING parquet PARTITIONED BY (DEST_COUNTRY_NAME)\n",
    "AS SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "| ORIGIN_COUNTRY_NAME|   string|   null|\n",
      "|               count|   bigint|   null|\n",
      "|   DEST_COUNTRY_NAME|   string|   null|\n",
      "|# Partition Infor...|         |       |\n",
      "|          # col_name|data_type|comment|\n",
      "|   DEST_COUNTRY_NAME|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe table partitioned_flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+\n",
      "|           col_name|data_type|comment|\n",
      "+-------------------+---------+-------+\n",
      "|  DEST_COUNTRY_NAME|   string|   null|\n",
      "|ORIGIN_COUNTRY_NAME|   string|   null|\n",
      "|              count|   bigint|   null|\n",
      "+-------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe table flights\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO partitioned_flights(count,ORIGIN_COUNTRY_NAME)\n",
    "  PARTITION (DEST_COUNTRY_NAME=\"UNITED STATES\")\n",
    "  SELECT count, ORIGIN_COUNTRY_NAME FROM flights\n",
    "  WHERE DEST_COUNTRY_NAME='UNITED STATES' LIMIT 12\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----------------+\n",
      "|ORIGIN_COUNTRY_NAME|count|DEST_COUNTRY_NAME|\n",
      "+-------------------+-----+-----------------+\n",
      "|      United States|   15|            Egypt|\n",
      "|            Romania|   15|    United States|\n",
      "|            Croatia|    1|    United States|\n",
      "|            Ireland|  344|    United States|\n",
      "|              India|   62|    United States|\n",
      "+-------------------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from partitioned_flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|partition                      |\n",
      "+-------------------------------+\n",
      "|DEST_COUNTRY_NAME=Egypt        |\n",
      "|DEST_COUNTRY_NAME=United States|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW PARTITIONS partitioned_flights\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCREATE EXTERNAL TABLE hive_flights (\\n  DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\\nROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/home/wengong/spark_data/data/flight-data-hive/'\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_stmt=f\"\"\"\n",
    "CREATE EXTERNAL TABLE hive_flights (\n",
    "  DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '{SPARK_BOOK_DATA_PATH}data/flight-data-hive/'\n",
    "\"\"\"\n",
    "sql_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(sql_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select * from hive_flights\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+\n",
      "|           col_name|data_type|comment|\n",
      "+-------------------+---------+-------+\n",
      "|  DEST_COUNTRY_NAME|   string|   null|\n",
      "|ORIGIN_COUNTRY_NAME|   string|   null|\n",
      "|              count|   bigint|   null|\n",
      "+-------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE TABLE hive_flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_stmt = f\"\"\"\n",
    "CREATE EXTERNAL TABLE hive_flights_2\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "LOCATION '{SPARK_BOOK_DATA_PATH}/data/flight-data-hive/' AS SELECT * FROM flights\n",
    "\"\"\"\n",
    "spark.sql(sql_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select * from hive_flights_2 limit 5\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from flights_from_select\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSERT INTO flights_from_select\n",
    "  SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"REFRESH table partitioned_flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- COMMAND ----------\n",
    "\n",
    "MSCK REPAIR TABLE partitioned_flights\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "DROP TABLE flights_csv;\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "DROP TABLE IF EXISTS flights_csv;\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "CACHE TABLE flights\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "UNCACHE TABLE FLIGHTS\n",
    "\n",
    "\n",
    "-- COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE VIEW just_usa_view AS \n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\")\n",
    "df = spark.sql(\"select * from just_usa_view limit 5\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- COMMAND ----------\n",
    "\n",
    "CREATE TEMP VIEW just_usa_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "CREATE GLOBAL TEMP VIEW just_usa_global_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW TABLES\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "CREATE OR REPLACE TEMP VIEW just_usa_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT * FROM just_usa_view_temp\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "EXPLAIN SELECT * FROM just_usa_view\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "EXPLAIN SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "DROP VIEW IF EXISTS just_usa_view;\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW DATABASES\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "CREATE DATABASE some_db\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "USE some_db\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW tables\n",
    "\n",
    "SELECT * FROM flights \n",
    "-- fails with table/view not found\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT * FROM default.flights\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "USE default;\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "DROP DATABASE IF EXISTS some_db;\n",
    "\n",
    "\n",
    "-- COMMAND ----------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "SELECT [ALL|DISTINCT] named_expression[, named_expression, ...]\n",
    "    FROM relation[, relation, ...]\n",
    "    [lateral_view[, lateral_view, ...]]\n",
    "    [WHERE boolean_expression]\n",
    "    [aggregation [HAVING boolean_expression]]\n",
    "    [ORDER BY sort_expressions]\n",
    "    [CLUSTER BY expressions]\n",
    "    [DISTRIBUTE BY expressions]\n",
    "    [SORT BY sort_expressions]\n",
    "    [WINDOW named_window[, WINDOW named_window, ...]]\n",
    "    [LIMIT num_rows]\n",
    "\n",
    "named_expression:\n",
    "    : expression [AS alias]\n",
    "\n",
    "relation:\n",
    "    | join_relation\n",
    "    | (table_name|query|relation) [sample] [AS alias]\n",
    "    : VALUES (expressions)[, (expressions), ...]\n",
    "          [AS (column_name[, column_name, ...])]\n",
    "\n",
    "expressions:\n",
    "    : expression[, expression, ...]\n",
    "\n",
    "sort_expressions:\n",
    "    : expression [ASC|DESC][, expression [ASC|DESC], ...]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- COMMAND ----------\n",
    "\n",
    "SELECT\n",
    "  CASE WHEN DEST_COUNTRY_NAME = 'UNITED STATES' THEN 1\n",
    "       WHEN DEST_COUNTRY_NAME = 'Egypt' THEN 0\n",
    "       ELSE -1 END\n",
    "FROM partitioned_flights\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS nested_data AS\n",
    "  SELECT (DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME) as country, count FROM flights\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT * FROM nested_data\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT country.DEST_COUNTRY_NAME, count FROM nested_data\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT country.*, count FROM nested_data\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT DEST_COUNTRY_NAME as new_name, collect_list(count) as flight_counts,\n",
    "  collect_set(ORIGIN_COUNTRY_NAME) as origin_set\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT DEST_COUNTRY_NAME as new_name, collect_list(count)[0]\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "  SELECT DEST_COUNTRY_NAME, collect_list(count) as collected_counts\n",
    "  FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW FUNCTIONS\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW SYSTEM FUNCTIONS\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW USER FUNCTIONS\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW FUNCTIONS \"s*\";\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SHOW FUNCTIONS LIKE \"collect*\";\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT count, power3(count) FROM flights\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT dest_country_name FROM flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT * FROM flights\n",
    "WHERE origin_country_name IN (SELECT dest_country_name FROM flights\n",
    "      GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT * FROM flights f1\n",
    "WHERE EXISTS (SELECT 1 FROM flights f2\n",
    "            WHERE f1.dest_country_name = f2.origin_country_name)\n",
    "AND EXISTS (SELECT 1 FROM flights f2\n",
    "            WHERE f2.dest_country_name = f1.origin_country_name)\n",
    "\n",
    "\n",
    "-- COMMAND ----------\n",
    "\n",
    "SELECT *, (SELECT max(count) FROM flights) AS maximum FROM flights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- COMMAND ----------\n",
    "\n",
    "SET spark.sql.shuffle.partitions=20\n",
    "\n",
    "\n",
    "-- COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
