{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1617417936.6752234, 1617417936675312591)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "t2 = time.time_ns()\n",
    "t1, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter-02-intro.ipynb\t\t   chapter-26-ML-classification.ipynb\r\n",
      "chapter-03-tour.ipynb\t\t   chapter-27-ML-regression.ipynb\r\n",
      "chapter-04-overview.ipynb\t   chapter-28-ML-recommender.ipynb\r\n",
      "chapter-05-basic-operation.ipynb   chapter-29-ML-clustering.ipynb\r\n",
      "chapter-06-types-functions.ipynb   chapter-30-graph-spark3.ipynb\r\n",
      "chapter-06-udf_datetime.ipynb\t   chapter-31-Deep-Learning.ipynb\r\n",
      "chapter-07-aggregation.ipynb\t   chapter-32-pandas.ipynb\r\n",
      "chapter-08-join.ipynb\t\t   chapter-33-delta.ipynb\r\n",
      "chapter-09-data-merge.ipynb\t   chapter-98-references.ipynb\r\n",
      "chapter-09-data-src.ipynb\t   chapter-99-tips_tricks.ipynb\r\n",
      "chapter-10-SQL.ipynb\t\t   derby.log\r\n",
      "chapter-12-RDD-basic.ipynb\t   html\r\n",
      "chapter-13-RDD-advanced.ipynb\t   kafka-tool.png\r\n",
      "chapter-14-broadcast-vars.ipynb    metastore_db\r\n",
      "chapter-15-cluster.ipynb\t   mock_csv_data.ipynb\r\n",
      "chapter-16-spark-app.ipynb\t   mp_files.csv\r\n",
      "chapter-19-perf.ipynb\t\t   mp_merge.csv\r\n",
      "chapter-21-stream.ipynb\t\t   mp_merge.parquet\r\n",
      "chapter-21-stream-kafka.ipynb\t   mp_meta.csv\r\n",
      "chapter-22-stream-stateful.ipynb   pdf\r\n",
      "chapter-23-stream-in-prod.ipynb    test.ipynb\r\n",
      "chapter-24-ML.ipynb\t\t   vt_merge.parquet\r\n",
      "chapter-25-ML-preprocessing.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\r\n",
      "Thu Apr 01 06:24:57 EDT 2021:\r\n",
      "Booting Derby version The Apache Software Foundation - Apache Derby - 10.12.1.1 - (1704137): instance a816c00e-0178-8cf6-f1f8-00003e4dbe10 \r\n",
      "on database directory /home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook/metastore_db with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@3c286028 \r\n",
      "Loaded from file:/home/wengong/spark/spark-3.0.1-bin-hadoop2.7/jars/derby-10.12.1.1.jar\r\n",
      "java.vendor=Azul Systems, Inc.\r\n",
      "java.runtime.version=1.8.0_262-b19\r\n",
      "user.dir=/home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook\r\n",
      "os.name=Linux\r\n",
      "os.arch=amd64\r\n",
      "os.version=5.8.0-48-generic\r\n",
      "derby.system.home=null\r\n",
      "Database Class Loader started - derby.database.classpath=''\r\n"
     ]
    }
   ],
   "source": [
    "!cat derby.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.read.text(\"derby.log\").rdd.map(lambda r: r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda x: x.split(' ')) \\\n",
    "        .map(lambda x: (x, len(x))) \n",
    "\n",
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('----------------------------------------------------------------', 64),\n",
       " ('Thu', 3),\n",
       " ('Apr', 3),\n",
       " ('01', 2),\n",
       " ('06:24:57', 8),\n",
       " ('EDT', 3),\n",
       " ('2021:', 5),\n",
       " ('Booting', 7),\n",
       " ('Derby', 5),\n",
       " ('version', 7)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 0),\n",
       " ('', 0),\n",
       " ('(1704137):', 10),\n",
       " ('-', 1),\n",
       " ('-', 1),\n",
       " ('-', 1),\n",
       " ('-', 1),\n",
       " ('----------------------------------------------------------------', 64),\n",
       " ('/home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook/metastore_db',\n",
       "  82),\n",
       " ('01', 2),\n",
       " ('06:24:57', 8),\n",
       " ('10.12.1.1', 9),\n",
       " ('2021:', 5),\n",
       " ('Apache', 6),\n",
       " ('Apache', 6),\n",
       " ('Apr', 3),\n",
       " ('Booting', 7),\n",
       " ('Class', 5),\n",
       " ('Database', 8),\n",
       " ('Derby', 5),\n",
       " ('Derby', 5),\n",
       " ('EDT', 3),\n",
       " ('Foundation', 10),\n",
       " ('Inc.', 4),\n",
       " ('Loaded', 6),\n",
       " ('Loader', 6),\n",
       " ('Software', 8),\n",
       " ('Systems,', 8),\n",
       " ('The', 3),\n",
       " ('Thu', 3),\n",
       " ('a816c00e-0178-8cf6-f1f8-00003e4dbe10', 36),\n",
       " ('class', 5),\n",
       " ('database', 8),\n",
       " (\"derby.database.classpath=''\", 27),\n",
       " ('derby.system.home=null', 22),\n",
       " ('directory', 9),\n",
       " ('file:/home/wengong/spark/spark-3.0.1-bin-hadoop2.7/jars/derby-10.12.1.1.jar',\n",
       "  75),\n",
       " ('from', 4),\n",
       " ('instance', 8),\n",
       " ('java.runtime.version=1.8.0_262-b19', 34),\n",
       " ('java.vendor=Azul', 16),\n",
       " ('loader', 6),\n",
       " ('on', 2),\n",
       " ('org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@3c286028',\n",
       "  70),\n",
       " ('os.arch=amd64', 13),\n",
       " ('os.name=Linux', 13),\n",
       " ('os.version=5.8.0-48-generic', 27),\n",
       " ('started', 7),\n",
       " ('user.dir=/home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook',\n",
       "  78),\n",
       " ('version', 7),\n",
       " ('with', 4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedByKey = words.sortBy(lambda a: a[0])\n",
    "\n",
    "sortedByKey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 0),\n",
       " ('', 0),\n",
       " ('-', 1),\n",
       " ('-', 1),\n",
       " ('-', 1),\n",
       " ('-', 1),\n",
       " ('01', 2),\n",
       " ('on', 2),\n",
       " ('Thu', 3),\n",
       " ('Apr', 3),\n",
       " ('EDT', 3),\n",
       " ('The', 3),\n",
       " ('with', 4),\n",
       " ('from', 4),\n",
       " ('Inc.', 4),\n",
       " ('2021:', 5),\n",
       " ('Derby', 5),\n",
       " ('Derby', 5),\n",
       " ('class', 5),\n",
       " ('Class', 5),\n",
       " ('Apache', 6),\n",
       " ('Apache', 6),\n",
       " ('loader', 6),\n",
       " ('Loaded', 6),\n",
       " ('Loader', 6),\n",
       " ('Booting', 7),\n",
       " ('version', 7),\n",
       " ('started', 7),\n",
       " ('06:24:57', 8),\n",
       " ('Software', 8),\n",
       " ('instance', 8),\n",
       " ('database', 8),\n",
       " ('Systems,', 8),\n",
       " ('Database', 8),\n",
       " ('10.12.1.1', 9),\n",
       " ('directory', 9),\n",
       " ('Foundation', 10),\n",
       " ('(1704137):', 10),\n",
       " ('os.name=Linux', 13),\n",
       " ('os.arch=amd64', 13),\n",
       " ('java.vendor=Azul', 16),\n",
       " ('derby.system.home=null', 22),\n",
       " ('os.version=5.8.0-48-generic', 27),\n",
       " (\"derby.database.classpath=''\", 27),\n",
       " ('java.runtime.version=1.8.0_262-b19', 34),\n",
       " ('a816c00e-0178-8cf6-f1f8-00003e4dbe10', 36),\n",
       " ('----------------------------------------------------------------', 64),\n",
       " ('org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@3c286028',\n",
       "  70),\n",
       " ('file:/home/wengong/spark/spark-3.0.1-bin-hadoop2.7/jars/derby-10.12.1.1.jar',\n",
       "  75),\n",
       " ('user.dir=/home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook',\n",
       "  78),\n",
       " ('/home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook/metastore_db',\n",
       "  82)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedByVal = words.sortBy(lambda a: a[1])\n",
    "\n",
    "sortedByVal.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 1), ('t', 3), ('b', 4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = sc.parallelize([('t', 3),('b', 4),('c', 1)])\n",
    "bSorted = b.sortBy(lambda a: a[1])\n",
    "bSorted.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"test\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"derby.log\"\n",
    "f = sc.textFile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = f.flatMap(lambda x: x.split(' ')).map(lambda x: (x, 1)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                  _1| _2|\n",
      "+--------------------+---+\n",
      "|-----------------...|  1|\n",
      "|                  03|  1|\n",
      "|               2021:|  1|\n",
      "|             Booting|  1|\n",
      "|             version|  1|\n",
      "|                 The|  1|\n",
      "|              Apache|  2|\n",
      "|          (1704137):|  1|\n",
      "|a816c00e-0178-985...|  1|\n",
      "|                    |  2|\n",
      "|            database|  1|\n",
      "|           directory|  1|\n",
      "|/home/wengong/pro...|  1|\n",
      "|               class|  1|\n",
      "|              loader|  1|\n",
      "|org.apache.spark....|  1|\n",
      "|    java.vendor=Azul|  1|\n",
      "|            Systems,|  1|\n",
      "|       os.name=Linux|  1|\n",
      "|               Class|  1|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wc.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.saveAsTextFile(\"wc_out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd wc_out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wengong/projects/py4kids/lesson-17-pyspark/spark-guide/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
