{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"chapter-07-aggregation\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "import os\n",
    "SPARK_BOOK_DATA_PATH = os.environ['SPARK_BOOK_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/2010 8:26|2.55     |17850     |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/2010 8:26|2.75     |17850     |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = SPARK_BOOK_DATA_PATH + \"/data/retail-data/all/*.csv\"\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(file_path)\\\n",
    "  .coalesce(3)\n",
    "\n",
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: string, UnitPrice: double, CustomerID: int, Country: string]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(InvoiceNo,StringType,true),StructField(StockCode,StringType,true),StructField(Description,StringType,true),StructField(Quantity,IntegerType,true),StructField(InvoiceDate,StringType,true),StructField(UnitPrice,DoubleType,true),StructField(CustomerID,IntegerType,true),StructField(Country,StringType,true)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = df.schema\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InvoiceNo',\n",
       " 'StockCode',\n",
       " 'Description',\n",
       " 'Quantity',\n",
       " 'InvoiceDate',\n",
       " 'UnitPrice',\n",
       " 'CustomerID',\n",
       " 'Country']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: string, UnitPrice: double, CustomerID: int, Country: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, True, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| Total|\n",
      "+------+\n",
      "|541909|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as Total from dfTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+\n",
      "|InvoiceNo|StockCode|         Description|\n",
      "+---------+---------+--------------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|\n",
      "|   536365|    71053| WHITE METAL LANTERN|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|\n",
      "+---------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select InvoiceNo,StockCode,Description from dfTable limit 3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|count(StockCode)|count(InvoiceDate)|\n",
      "+----------------+------------------+\n",
      "|          541909|            541909|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.select(F.count(\"StockCode\"), F.count(\"InvoiceDate\")).show() # 541909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|   541909|   541909|     540455|  541909|     541909|   541909|    406829| 541909|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use count to detect columns with null\n",
    "df.agg(*[F.count(c).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+--------------+------------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|InvoiceDate_ts|Invoice_Date|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+--------------+------------+\n",
      "|    25900|     4070|       4223|     722|      23260|     1630|      4372|     38|         23260|         305|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use countDistinct for unique values in each column\n",
    "df.agg(*[F.countDistinct(c).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+--------------+------------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|InvoiceDate_ts|Invoice_Date|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+--------------+------------+\n",
      "|    25085|     3364|       4240|     698|      23267|     1694|      4336|     33|         23938|         338|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use approx_count_distinct to estimate counts quickly\n",
    "df.agg(*[F.approx_count_distinct(c, 0.1).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "udf_to_date =  F.udf (lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M'), DateType())\n",
    "udf_to_datetime =  F.udf (lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M'), TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change InvoiceDate format\n",
    "df = (df\n",
    "      .withColumn(\"InvoiceDate_ts\", udf_to_datetime(F.col(\"InvoiceDate\")))\n",
    "      .withColumn(\"Invoice_Date\", udf_to_date(F.col(\"InvoiceDate\")))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------\n",
      " InvoiceNo      | 536365                              \n",
      " StockCode      | 85123A                              \n",
      " Description    | WHITE HANGING HEART T-LIGHT HOLDER  \n",
      " Quantity       | 6                                   \n",
      " InvoiceDate    | 12/1/2010 8:26                      \n",
      " UnitPrice      | 2.55                                \n",
      " CustomerID     | 17850                               \n",
      " Country        | United Kingdom                      \n",
      " InvoiceDate_ts | 2010-12-01 08:26:00                 \n",
      " Invoice_Date   | 2010-12-01                          \n",
      "-RECORD 1---------------------------------------------\n",
      " InvoiceNo      | 536365                              \n",
      " StockCode      | 71053                               \n",
      " Description    | WHITE METAL LANTERN                 \n",
      " Quantity       | 6                                   \n",
      " InvoiceDate    | 12/1/2010 8:26                      \n",
      " UnitPrice      | 3.39                                \n",
      " CustomerID     | 17850                               \n",
      " Country        | United Kingdom                      \n",
      " InvoiceDate_ts | 2010-12-01 08:26:00                 \n",
      " Invoice_Date   | 2010-12-01                          \n",
      "-RECORD 2---------------------------------------------\n",
      " InvoiceNo      | 536365                              \n",
      " StockCode      | 84406B                              \n",
      " Description    | CREAM CUPID HEARTS COAT HANGER      \n",
      " Quantity       | 8                                   \n",
      " InvoiceDate    | 12/1/2010 8:26                      \n",
      " UnitPrice      | 2.75                                \n",
      " CustomerID     | 17850                               \n",
      " Country        | United Kingdom                      \n",
      " InvoiceDate_ts | 2010-12-01 08:26:00                 \n",
      " Invoice_Date   | 2010-12-01                          \n",
      "-RECORD 3---------------------------------------------\n",
      " InvoiceNo      | 536365                              \n",
      " StockCode      | 84029G                              \n",
      " Description    | KNITTED UNION FLAG HOT WATER BOTTLE \n",
      " Quantity       | 6                                   \n",
      " InvoiceDate    | 12/1/2010 8:26                      \n",
      " UnitPrice      | 3.39                                \n",
      " CustomerID     | 17850                               \n",
      " Country        | United Kingdom                      \n",
      " InvoiceDate_ts | 2010-12-01 08:26:00                 \n",
      " Invoice_Date   | 2010-12-01                          \n",
      "-RECORD 4---------------------------------------------\n",
      " InvoiceNo      | 536365                              \n",
      " StockCode      | 84029E                              \n",
      " Description    | RED WOOLLY HOTTIE WHITE HEART.      \n",
      " Quantity       | 6                                   \n",
      " InvoiceDate    | 12/1/2010 8:26                      \n",
      " UnitPrice      | 3.39                                \n",
      " CustomerID     | 17850                               \n",
      " Country        | United Kingdom                      \n",
      " InvoiceDate_ts | 2010-12-01 08:26:00                 \n",
      " Invoice_Date   | 2010-12-01                          \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|StockCode|count(StockCode)|\n",
      "+---------+----------------+\n",
      "|22728    |810             |\n",
      "|21889    |607             |\n",
      "|90210B   |7               |\n",
      "|21259    |296             |\n",
      "|21894    |135             |\n",
      "|21452    |200             |\n",
      "|22121    |141             |\n",
      "|90022    |21              |\n",
      "|21249    |119             |\n",
      "|90143    |22              |\n",
      "+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"StockCode\").agg(F.expr(\"count(StockCode)\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------------------------+--------+----------------+---------+----------+--------------+-------------------+------------+\n",
      "|InvoiceNo|StockCode|Description                      |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country       |InvoiceDate_ts     |Invoice_Date|\n",
      "+---------+---------+---------------------------------+--------+----------------+---------+----------+--------------+-------------------+------------+\n",
      "|577315   |90026D   |GLASS BEAD HOOP NECKLACE AMETHYST|1       |11/18/2011 13:25|8.5      |17811     |United Kingdom|2011-11-18 13:25:00|2011-11-18  |\n",
      "|548545   |90026D   |GLASS BEAD HOOP NECKLACE AMETHYST|1       |3/31/2011 19:12 |8.5      |13118     |United Kingdom|2011-03-31 19:12:00|2011-03-31  |\n",
      "|544463   |90026D   |GLASS BEAD HOOP NECKLACE AMETHYST|1       |2/20/2011 14:31 |8.5      |12988     |United Kingdom|2011-02-20 14:31:00|2011-02-20  |\n",
      "|581434   |90210B   |CLEAR ACRYLIC FACETED BANGLE     |10      |12/8/2011 16:10 |1.0      |13599     |United Kingdom|2011-12-08 16:10:00|2011-12-08  |\n",
      "|573102   |90210B   |CLEAR ACRYLIC FACETED BANGLE     |10      |10/27/2011 14:52|1.0      |13266     |United Kingdom|2011-10-27 14:52:00|2011-10-27  |\n",
      "|568787   |90210B   |CLEAR ACRYLIC FACETED BANGLE     |6       |9/29/2011 9:19  |2.95     |13741     |United Kingdom|2011-09-29 09:19:00|2011-09-29  |\n",
      "|538661   |90210B   |CLEAR ACRYLIC FACETED BANGLE     |12      |12/13/2010 15:42|1.25     |15194     |United Kingdom|2010-12-13 15:42:00|2010-12-13  |\n",
      "|538071   |90210B   |CLEAR ACRYLIC FACETED BANGLE     |1       |12/9/2010 14:09 |2.96     |null      |United Kingdom|2010-12-09 14:09:00|2010-12-09  |\n",
      "|537045   |90210B   |CLEAR ACRYLIC FACETED BANGLE     |1       |12/5/2010 10:54 |2.95     |15038     |United Kingdom|2010-12-05 10:54:00|2010-12-05  |\n",
      "|536409   |90210B   |CLEAR ACRYLIC FACETED BANGLE     |1       |12/1/2010 11:45 |2.95     |17908     |United Kingdom|2010-12-01 11:45:00|2010-12-01  |\n",
      "+---------+---------+---------------------------------+--------+----------------+---------+----------+--------------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.where(\"StockCode in ('90026D', '90210B') \").orderBy(\"StockCode\", desc(\"InvoiceDate\")).show(10, False)\n",
    "df.where(\"StockCode in ('90026D', '90210B') \").orderBy(\"StockCode\", F.desc(\"InvoiceDate_ts\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            3364|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# from pyspark.sql.functions import approx_count_distinct\n",
    "df.select(F.approx_count_distinct(\"StockCode\", 0.1)).show() # 3364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+\n",
      "|first(StockCode)|last(StockCode)|\n",
      "+----------------+---------------+\n",
      "|          85123A|          22138|\n",
      "+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# from pyspark.sql.functions import first, last\n",
    "df.select(F.first(\"StockCode\"), F.last(\"StockCode\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|min(Quantity)|max(Quantity)|\n",
      "+-------------+-------------+\n",
      "|       -80995|        80995|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# from pyspark.sql.functions import min, max\n",
    "df.select(F.min(\"Quantity\"), F.max(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|sum(Quantity)|\n",
      "+-------------+\n",
      "|      5176450|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# from pyspark.sql.functions import sum\n",
    "df.select(F.sum(\"Quantity\")).show() # 5176450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|sum(DISTINCT Quantity)|\n",
      "+----------------------+\n",
      "|                 29310|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# from pyspark.sql.functions import sumDistinct\n",
    "df.select(F.sumDistinct(\"Quantity\")).show() # 29310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " avg_purchase   | 9.55224954743324 \n",
      " avg_purchases  | 9.55224954743324 \n",
      " mean_purchases | 9.55224954743324 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# from pyspark.sql.functions import sum, count, avg, expr\n",
    "\n",
    "(df.select(\n",
    "    F.count(\"Quantity\").alias(\"total_transactions\"),\n",
    "    F.sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "    F.avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "    F.expr(\"mean(Quantity)\").alias(\"mean_purchases\"))\n",
    "  .selectExpr(\n",
    "    \"total_purchases/total_transactions as avg_purchase\",\n",
    "    \"avg_purchases\",\n",
    "    \"mean_purchases\")\n",
    " .show(vertical=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+---------------------+\n",
      "|var_pop(Quantity)|var_samp(Quantity)|stddev_pop(Quantity)|stddev_samp(Quantity)|\n",
      "+-----------------+------------------+--------------------+---------------------+\n",
      "|47559.30364660928| 47559.39140929898|  218.08095663447847|    218.0811578502347|\n",
      "+-----------------+------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import var_pop, stddev_pop\n",
    "from pyspark.sql.functions import var_samp, stddev_samp\n",
    "df.select(var_pop(\"Quantity\"), \n",
    "          var_samp(\"Quantity\"),\n",
    "          stddev_pop(\"Quantity\"), \n",
    "          stddev_samp(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|  skewness(Quantity)|kurtosis(Quantity)|\n",
      "+--------------------+------------------+\n",
      "|-0.26407557610528154|  119768.054955306|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import skewness, kurtosis\n",
    "df.select(skewness(\"Quantity\"), kurtosis(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|corr(InvoiceNo, Quantity)|covar_samp(InvoiceNo, Quantity)|covar_pop(InvoiceNo, Quantity)|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|     4.912186085639875E-4|             1052.7280543916152|             1052.726077875511|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import corr, covar_pop, covar_samp\n",
    "df.select(\n",
    "        corr(\"InvoiceNo\", \"Quantity\"), \n",
    "        covar_samp(\"InvoiceNo\", \"Quantity\"),\n",
    "        covar_pop(\"InvoiceNo\", \"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|corr(UnitPrice, Quantity)|covar_samp(UnitPrice, Quantity)|covar_pop(UnitPrice, Quantity)|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|     -0.00123492454487...|             -26.05876125793698|           -26.058713170968026|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "        corr(\"UnitPrice\", \"Quantity\"), \n",
    "        covar_samp(\"UnitPrice\", \"Quantity\"),\n",
    "        covar_pop(\"UnitPrice\", \"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|collect_set(Country)                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Portugal, Italy, Finland, Germany, Canada, RSA, Switzerland, Greece, Spain, Sweden, Hong Kong, Singapore, Lebanon, Belgium, Cyprus, United Arab Emirates, Australia, Denmark, United Kingdom, Japan, Iceland, Unspecified, Lithuania, EIRE, Bahrain, Austria, Poland, Brazil, Malta, Saudi Arabia, Netherlands, France, Channel Islands, European Community, Norway, Israel, USA, Czech Republic]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(F.collect_set(\"Country\")).show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------------+\n",
      "|InvoiceNo|quan|count(Quantity)|\n",
      "+---------+----+---------------+\n",
      "|   536596|   6|              6|\n",
      "|   536938|  14|             14|\n",
      "|   537252|   1|              1|\n",
      "|   537691|  20|             20|\n",
      "|   538041|   1|              1|\n",
      "|   538184|  26|             26|\n",
      "|   538517|  53|             53|\n",
      "|   538879|  19|             19|\n",
      "|   539275|   6|              6|\n",
      "|   539630|  12|             12|\n",
      "|   540499|  24|             24|\n",
      "|   540540|  22|             22|\n",
      "|  C540850|   1|              1|\n",
      "|   540976|  48|             48|\n",
      "|   541432|   4|              4|\n",
      "|   541518| 101|            101|\n",
      "|   541783|  35|             35|\n",
      "|   542026|   9|              9|\n",
      "|   542375|   6|              6|\n",
      "|  C542604|   8|              8|\n",
      "+---------+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df.groupBy(\"InvoiceNo\").agg(\n",
    "    count(\"Quantity\").alias(\"quan\"),\n",
    "    expr(\"count(Quantity)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------------+\n",
      "|InvoiceNo|     avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+------------------+--------------------+\n",
      "|   536596|               1.5|  1.1180339887498947|\n",
      "|   536938|33.142857142857146|  20.698023172885524|\n",
      "|   537252|              31.0|                 0.0|\n",
      "|   537691|              8.15|   5.597097462078001|\n",
      "|   538041|              30.0|                 0.0|\n",
      "|   538184|12.076923076923077|   8.142590198943392|\n",
      "|   538517|3.0377358490566038|  2.3946659604837897|\n",
      "|   538879|21.157894736842106|  11.811070444356483|\n",
      "|   539275|              26.0|  12.806248474865697|\n",
      "|   539630|20.333333333333332|  10.225241100118645|\n",
      "|   540499|              3.75|  2.6653642652865788|\n",
      "|   540540|2.1363636363636362|  1.0572457590557278|\n",
      "|  C540850|              -1.0|                 0.0|\n",
      "|   540976|10.520833333333334|   6.496760677872902|\n",
      "|   541432|             12.25|  10.825317547305483|\n",
      "|   541518| 23.10891089108911|  20.550782784878713|\n",
      "|   541783|11.314285714285715|   8.467657556242811|\n",
      "|   542026| 7.666666666666667|   4.853406592853679|\n",
      "|   542375|               8.0|  3.4641016151377544|\n",
      "|  C542604|              -8.0|  15.173990905493518|\n",
      "+---------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.groupBy(\"InvoiceNo\").agg(\n",
    "        expr(\"avg(Quantity)\"),\n",
    "        expr(\"stddev_pop(Quantity)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import col, to_date\n",
    "# dfWithDate = df.withColumn(\"date\", to_date(col(\"InvoiceDate\"), \"MM/dd/yyyy HH:mm\"))\n",
    "dfWithDate = df.withColumn(\"date\", udf_to_datetime(col(\"InvoiceDate\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+---------------+-------------------+-------------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |InvoiceDate_std|InvoiceDate_ts     |date               |\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+---------------+-------------------+-------------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/2010 8:26|2.55     |17850     |United Kingdom|null           |2010-12-01 08:26:00|2010-12-01 08:26:00|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|null           |2010-12-01 08:26:00|2010-12-01 08:26:00|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/2010 8:26|2.75     |17850     |United Kingdom|null           |2010-12-01 08:26:00|2010-12-01 08:26:00|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|null           |2010-12-01 08:26:00|2010-12-01 08:26:00|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|null           |2010-12-01 08:26:00|2010-12-01 08:26:00|\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+---------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithDate.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithDate.createOrReplaceTempView(\"dfWithDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc\n",
    "windowSpec = Window\\\n",
    "  .partitionBy(\"CustomerId\", \"date\")\\\n",
    "  .orderBy(desc(\"Quantity\"))\\\n",
    "  .rowsBetween(Window.unboundedPreceding, Window.currentRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import max\n",
    "maxPurchaseQuantity = max(F.col(\"Quantity\")).over(windowSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import dense_rank, rank\n",
    "purchaseDenseRank = dense_rank().over(windowSpec)\n",
    "purchaseRank = rank().over(windowSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------+------------+-----------------+-------------------+\n",
      "|CustomerId|               date|Quantity|quantityRank|quantityDenseRank|maxPurchaseQuantity|\n",
      "+----------+-------------------+--------+------------+-----------------+-------------------+\n",
      "|     12346|2011-01-18 10:01:00|   74215|           1|                1|              74215|\n",
      "|     12346|2011-01-18 10:17:00|  -74215|           1|                1|             -74215|\n",
      "|     12347|2010-12-07 14:57:00|      36|           1|                1|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      30|           2|                2|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      24|           3|                3|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07 14:57:00|       6|          17|                5|                 36|\n",
      "|     12347|2010-12-07 14:57:00|       6|          17|                5|                 36|\n",
      "+----------+-------------------+--------+------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dfWithDate.where(\"CustomerId IS NOT NULL\").orderBy(\"CustomerId\")\\\n",
    "  .select(\n",
    "    col(\"CustomerId\"),\n",
    "    col(\"date\"),\n",
    "    col(\"Quantity\"),\n",
    "    purchaseRank.alias(\"quantityRank\"),\n",
    "    purchaseDenseRank.alias(\"quantityDenseRank\"),\n",
    "    maxPurchaseQuantity.alias(\"maxPurchaseQuantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "dfNoNull = dfWithDate.drop()\n",
    "dfNoNull.createOrReplaceTempView(\"dfNoNull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+--------------+\n",
      "|               Date|       Country|total_quantity|\n",
      "+-------------------+--------------+--------------+\n",
      "|               null|          null|       5176450|\n",
      "|2010-12-01 08:26:00|United Kingdom|            40|\n",
      "|2010-12-01 08:26:00|          null|            40|\n",
      "|2010-12-01 08:28:00|United Kingdom|            12|\n",
      "|2010-12-01 08:28:00|          null|            12|\n",
      "|2010-12-01 08:34:00|          null|            98|\n",
      "|2010-12-01 08:34:00|United Kingdom|            98|\n",
      "|2010-12-01 08:35:00|          null|             3|\n",
      "|2010-12-01 08:35:00|United Kingdom|             3|\n",
      "|2010-12-01 08:45:00|        France|           449|\n",
      "|2010-12-01 08:45:00|          null|           449|\n",
      "|2010-12-01 09:00:00|United Kingdom|            80|\n",
      "|2010-12-01 09:00:00|          null|            80|\n",
      "|2010-12-01 09:01:00|United Kingdom|            12|\n",
      "|2010-12-01 09:01:00|          null|            12|\n",
      "|2010-12-01 09:02:00|          null|            88|\n",
      "|2010-12-01 09:02:00|United Kingdom|            88|\n",
      "|2010-12-01 09:09:00|United Kingdom|            32|\n",
      "|2010-12-01 09:09:00|          null|            32|\n",
      "|2010-12-01 09:32:00|United Kingdom|           200|\n",
      "+-------------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "rolledUpDF = dfNoNull.rollup(\"Date\", \"Country\").agg(sum(\"Quantity\"))\\\n",
    "  .selectExpr(\"Date\", \"Country\", \"`sum(Quantity)` as total_quantity\")\\\n",
    "  .orderBy(\"Date\")\n",
    "rolledUpDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------------+---------------+\n",
      "|Date|             Country|sum(Quantity)|count(Quantity)|\n",
      "+----+--------------------+-------------+---------------+\n",
      "|null|               Japan|        25218|            358|\n",
      "|null|            Portugal|        16180|           1519|\n",
      "|null|           Australia|        83653|           1259|\n",
      "|null|                 RSA|          352|             58|\n",
      "|null|                null|      5176450|         541909|\n",
      "|null|         Unspecified|         3300|            446|\n",
      "|null|             Finland|        10666|            695|\n",
      "|null|           Hong Kong|         4769|            288|\n",
      "|null|             Germany|       117448|           9495|\n",
      "|null|             Lebanon|          386|             45|\n",
      "|null|              Cyprus|         6317|            622|\n",
      "|null|           Singapore|         5234|            229|\n",
      "|null|United Arab Emirates|          982|             68|\n",
      "|null|     Channel Islands|         9479|            758|\n",
      "|null|             Denmark|         8188|            389|\n",
      "|null|               Spain|        26824|           2533|\n",
      "|null|  European Community|          497|             61|\n",
      "|null|              Norway|        19247|           1086|\n",
      "|null|                 USA|         1034|            291|\n",
      "|null|      Czech Republic|          592|             30|\n",
      "+----+--------------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "dfNoNull.cube(\"Date\", \"Country\")\\\n",
    "    .agg(sum(col(\"Quantity\")), count(col(\"Quantity\")))\\\n",
    "    .select(\"Date\", \"Country\", \"sum(Quantity)\", \"count(Quantity)\")\\\n",
    "    .orderBy(\"Date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "pivoted = dfWithDate.groupBy(\"date\").pivot(\"Country\").sum()\n",
    "\n",
    "\n",
    "# COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|category|\n",
      "+---+--------+\n",
      "|  1|       a|\n",
      "|  1|       a|\n",
      "|  2|       a|\n",
      "|  1|       b|\n",
      "|  2|       b|\n",
      "|  3|       b|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, \"a\"), (1, \"a\"), (2, \"a\"), (1, \"b\"), (2, \"b\"), (3, \"b\")]\n",
    "columns = [\"id\", \"category\"]\n",
    "df=spark.createDataFrame(data=data,schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (Window.partitionBy(\"category\")\n",
    "        .orderBy(\"id\")\n",
    "        .rangeBetween(Window.currentRow, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+\n",
      "|category| id|sum|\n",
      "+--------+---+---+\n",
      "|       a|  1|  4|\n",
      "|       a|  1|  4|\n",
      "|       a|  2|  2|\n",
      "|       b|  1|  3|\n",
      "|       b|  2|  5|\n",
      "|       b|  3|  3|\n",
      "+--------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (df.withColumn(\"sum\", F.sum(\"id\").over(window))\n",
    "    .sort(\"category\", \"id\")\n",
    "     )\n",
    "df.select(\"category\",\"id\",\"sum\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, False, False, False, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n",
      "| id|category|sum|\n",
      "+---+--------+---+\n",
      "|  1|       a|  4|\n",
      "|  1|       a|  4|\n",
      "|  2|       a|  2|\n",
      "|  1|       b|  3|\n",
      "|  2|       b|  5|\n",
      "|  3|       b|  3|\n",
      "+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+\n",
      "|  id|category|count|\n",
      "+----+--------+-----+\n",
      "|null|    null|    6|\n",
      "|   1|    null|    3|\n",
      "|   2|    null|    2|\n",
      "|   3|    null|    1|\n",
      "|   1|       a|    2|\n",
      "|   2|       a|    1|\n",
      "|   1|       b|    1|\n",
      "|   2|       b|    1|\n",
      "|   3|       b|    1|\n",
      "+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.rollup(\"id\",\"category\").count().orderBy(\"category\",\"id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+\n",
      "|  id|category|count|\n",
      "+----+--------+-----+\n",
      "|null|    null|    6|\n",
      "|   1|    null|    3|\n",
      "|   2|    null|    2|\n",
      "|   3|    null|    1|\n",
      "|null|       a|    3|\n",
      "|   1|       a|    2|\n",
      "|   2|       a|    1|\n",
      "|null|       b|    3|\n",
      "|   1|       b|    1|\n",
      "|   2|       b|    1|\n",
      "|   3|       b|    1|\n",
      "+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cube(\"id\",\"category\").count().orderBy(\"category\",\"id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
