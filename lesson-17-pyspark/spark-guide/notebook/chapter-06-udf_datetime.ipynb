{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark UDF \n",
    "\n",
    "(a.k.a User Defined Function) is the most useful feature of Spark SQL & DataFrame that is used to extend the PySpark build in capabilities.\n",
    "\n",
    "https://sparkbyexamples.com/pyspark/pyspark-udf-user-defined-function/#converting-udf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"chapter-06-convert-datetime-utf\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unix_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"11/25/1991\",), (\"01/24/1991\",), (\"02/03/1919\",)], \n",
    "    ['date_str']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  date_str|\n",
      "+----------+\n",
      "|11/25/1991|\n",
      "|01/24/1991|\n",
      "|02/03/1919|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df.select(\n",
    "    'date_str', \n",
    "    F.from_unixtime(F.unix_timestamp('date_str', 'MM/dd/yyyy')).alias('date')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_str: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is wrong that `date` datatype is still `string`, but its value is in correct `datetime` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|  date_str|               date|\n",
      "+----------+-------------------+\n",
      "|11/25/1991|1991-11-25 00:00:00|\n",
      "|01/24/1991|1991-01-24 00:00:00|\n",
      "|02/03/1919|1919-02-03 00:00:00|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = df.select(\n",
    "    'date_str', \n",
    "    F.to_date('date_str', 'MM/dd/yyyy').alias('date')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|  date_str|      date|\n",
      "+----------+----------+\n",
      "|11/25/1991|1991-11-25|\n",
      "|01/24/1991|1991-01-24|\n",
      "|02/03/1919|1919-02-03|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_str: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_b.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"11/25/1991 01:30:10\",), (\"01/24/1991 11:30:10\",), (\"02/03/1919 21:30:10\",)], \n",
    "    ['date_str']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.select(\n",
    "    'date_str', \n",
    "    F.to_timestamp('date_str', 'MM/dd/yyyy HH:mm:SS').alias('date')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+\n",
      "|date_str           |date                 |\n",
      "+-------------------+---------------------+\n",
      "|11/25/1991 01:30:10|1991-11-25 01:30:00.1|\n",
      "|01/24/1991 11:30:10|1991-01-24 11:30:00.1|\n",
      "|02/03/1919 21:30:10|1919-02-03 21:30:00.1|\n",
      "+-------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_c.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_str: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_c.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "spark.sparkContext._conf.setAll([(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")])\n",
    "\n",
    "spark.sparkContext._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF - to_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(\n",
    "    [(\"11/25/1991\",), (\"1/24/1991\",), (\"2/3/1919\",)], \n",
    "    ['date_str']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  date_str|\n",
      "+----------+\n",
      "|11/25/1991|\n",
      "| 1/24/1991|\n",
      "|  2/3/1919|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "udf_to_date =  F.udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_a = df2.withColumn('date', udf_to_date(F.col('date_str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|  date_str|      date|\n",
      "+----------+----------+\n",
      "|11/25/1991|1991-11-25|\n",
      "| 1/24/1991|1991-01-24|\n",
      "|  2/3/1919|1919-02-03|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_str: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_a.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF - to_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf_to_datetime =  F.udf (lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M:%S'), DateType())\n",
    "udf_to_datetime =  F.udf (lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M'), TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.createDataFrame(\n",
    "    [(\"11/25/1991 1:15\",), (\"1/24/1991 12:30\",), (\"2/3/1919 18:00\",)], \n",
    "    ['datetime_str']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_a = df3.withColumn('timestamp', udf_to_datetime(F.col('datetime_str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|   datetime_str|          timestamp|\n",
      "+---------------+-------------------+\n",
      "|11/25/1991 1:15|1991-11-25 01:15:00|\n",
      "|1/24/1991 12:30|1991-01-24 12:30:00|\n",
      "| 2/3/1919 18:00|1919-02-03 18:00:00|\n",
      "+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3_a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime_str: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3_a.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
